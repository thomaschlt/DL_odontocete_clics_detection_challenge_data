{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div align=\"center\" >\n",
    "\n",
    "![Confusion Matrix](../images/ENSC.png)\n",
    "\n",
    "# <u> ENSC Parcours IA </u>\n",
    "## Data Challenge - Détection de clics d'odontocètes\n",
    "\n",
    "</div>\n",
    "\n",
    "As part of the [Artificial Intelligence specialization](https://3aia.notion.site/3aia/Parcours-3A-IA-2023-9917027c682b457dae71fea68c067ad1) at the [ENSC](https://ensc.bordeaux-inp.fr/fr), we participated in a data challenge provided by the University of Toulon in the [ChallengeData](https://challengedata.ens.fr/) website. \n",
    "\n",
    "This challenge specifically aims to detect the presence of odontoceti clicks in underwater audio recordings in the Caribbean sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature as feat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import signal\n",
    "import reservoirpy as rp\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils import retrieve_hyper_params_from_json, load_and_preprocess_data, load_and_preprocess_data_augmented\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ===== Set parameters ======\n",
    "grandparent_dir = Path.cwd().parents[0]\n",
    "print(grandparent_dir)\n",
    "test_directory = grandparent_dir / \".dataset\" / \"X_test\"\n",
    "train_directory = grandparent_dir / \".dataset\" / \"X_train\"\n",
    "\n",
    "# Set the path to the downloaded data\n",
    "download_path = grandparent_dir / \".dataset\"\n",
    "\n",
    "# Audio parameters\n",
    "sample_rate = 256000\n",
    "audio_duration_seconds = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ====== Load and preprocess data ====== \n",
    "# Read labels file\n",
    "labels_file = download_path / \"Y_train_ofTdMHi.csv\"\n",
    "df = pd.read_csv(labels_file)\n",
    "\n",
    "# Construct file path by concatenating folder and file name\n",
    "df[\"relative_path\"] = Path(download_path) / \"X_train\" / df[\"id\"]\n",
    "# df[\"relative_path\"] = str(download_path) + \"/X_train/\" + df[\"id\"]\n",
    "\n",
    "# Drop id column (replaced it with relative_path)\n",
    "df.drop(columns=[\"id\"], inplace=True)\n",
    "\n",
    "df.rename(columns={\"pos_label\": \"label\"}, inplace=True)\n",
    "\n",
    "# invert relative_path and label columns positions\n",
    "df = df[[\"relative_path\", \"label\"]]\n",
    "print(f\"### There are {len(df)} audio files in the dataset.\")\n",
    "\n",
    "table = f\"\"\"\n",
    "Here is the split into good and bad signals:\n",
    "| Label   | Count   |\n",
    "|:-------:|:-------:|\n",
    "| 0       | {df['label'].value_counts()[0]:7} |\n",
    "| 1       | {df['label'].value_counts()[1]:7} |\"\"\"\n",
    "print(table, end=\"\\n\\n\")\n",
    "print(\"### Here is a sample of the data:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_length = int(sample_rate * audio_duration_seconds)\n",
    "# X = load_and_preprocess_data(df, target_length)\n",
    "data, labels = load_and_preprocess_data_augmented(df, target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels.astype(int)\n",
    "y[:5],y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "y = np.eye(2)[y]\n",
    "y[:5], y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the training and test data & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = round(data.shape[0]*0.8)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, y)\n",
    "\n",
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# with open(\"hyperopt-odontoceti-2/results/0.4222609_hyperopt_results_1call.json\", \"r\") as f:\n",
    "#     y = json.load(f)\n",
    "\n",
    "# print(y['current_params'])\n",
    "# retrieve N, iss, lr, ridge, seed, sr from y['current_params']\n",
    "# N, iss, lr, ridge, seed, sr = retrieve_hyper_params_from_json(\"hyperopt-odontoceti-2/results/0.4222609_hyperopt_results_1call.json\")\n",
    "N, iss, lr, ridge, seed, sr = 1000, 0.9, 0.6571588388986349, 0.002820052832209098, 1234, 0.051153084643003444\n",
    "\n",
    "print(N, iss, lr, ridge, seed, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.nodes import Reservoir, Ridge, Input\n",
    "\n",
    "source = Input()\n",
    "reservoir = Reservoir(N, sr=sr, lr=lr, iss=iss, seed=seed)\n",
    "readout = Ridge(ridge=ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_states = reservoir.run(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout.fit(train_states, train_labels, warmup=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_states = reservoir.run(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = readout.run(test_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred[Y_pred > 1] = 1\n",
    "Y_pred[Y_pred < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(Y_pred, axis=1)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy\n",
    "Y_pred_class = [np.argmax(y_p) for y_p in Y_pred]\n",
    "Y_test_class = [np.argmax(y_t) for y_t in test_labels]\n",
    "\n",
    "accuracy = accuracy_score(Y_test_class, Y_pred_class)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(Y_test_class, Y_pred_class)\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(Y_test_class, Y_pred_class)\n",
    "print(f\"ROC AUC score: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,5))\n",
    "# import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(Y_test_class, Y_pred_class))\n",
    "\n",
    "# plot confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(Y_test_class, Y_pred_class)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"good\", \"bad\"])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(folder_path, target_length):\n",
    "    file_paths = list(Path(folder_path).rglob('*.wav'))  # Assuming the audio files are in WAV format\n",
    "    return load_and_preprocess_data(file_paths, target_length)\n",
    "\n",
    "test_directory = Path.cwd() / \"../\" / \".dataset\" / \"X_test\"\n",
    "print(test_directory)\n",
    "X_test = load_test_data(test_directory, target_length)\n",
    "submission_states = reservoir.run(X_test)\n",
    "\n",
    "predictions = readout.run(submission_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(predictions, axis=1)[:10])\n",
    "submission_predictions = np.max(predictions, axis=1)\n",
    "f\"First prediction is {submission_predictions[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [file_path.name for file_path in Path(test_directory).rglob('*.wav')]\n",
    "\n",
    "df = pd.DataFrame({'id': file_names, 'pos_label': submission_predictions[:]})\n",
    "df.to_csv(\"reservoir_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        return []\n",
    "\n",
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_states.shape, train_labels.shape, test_states.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (train_states, train_labels, test_states, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.observables import nrmse, rsquare\n",
    "from reservoirpy.nodes import Reservoir, Ridge, Input\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Objective functions accepted by ReservoirPy must respect some conventions:\n",
    "#  - dataset and config arguments are mandatory, like the empty '*' expression.\n",
    "#  - all parameters that will be used during the search must be placed after the *.\n",
    "#  - the function must return a dict with at least a 'loss' key containing the result\n",
    "# of the loss function. You can add any additional metrics or information with other \n",
    "# keys in the dict. See hyperopt documentation for more informations.\n",
    "def objective(dataset, config, *, iss, N, sr, lr, ridge, seed):\n",
    "    \n",
    "    # This step may vary depending on what you put inside 'dataset'\n",
    "    (X_train, y_train, X_test, y_test) = dataset\n",
    "    \n",
    "    # You can access anything you put in the config \n",
    "    # file from the 'config' parameter.\n",
    "    instances = config[\"instances_per_trial\"]\n",
    "    \n",
    "    # The seed should be changed across the instances, \n",
    "    # to be sure there is no bias in the results \n",
    "    # due to initialization.\n",
    "    variable_seed = seed \n",
    "    \n",
    "    losses = []; r2s = [];\n",
    "    for n in range(instances):\n",
    "        # Build your model given the input parameters\n",
    "        reservoir = Reservoir(N, \n",
    "                              sr=sr, \n",
    "                              lr=lr, \n",
    "                              inut_scaling=iss, \n",
    "                              seed=variable_seed)\n",
    "        \n",
    "        readout = Ridge(ridge=ridge)\n",
    "\n",
    "        # model = reservoir >> readout\n",
    "        model = [source >> reservoir, source >> reservoir, source] >> readout\n",
    "\n",
    "\n",
    "        # Train your model and test your model.\n",
    "        predictions = model.fit(X_train, y_train) \\\n",
    "                           .run(X_test)\n",
    "        \n",
    "\n",
    "        Y_pred_class = [np.argmax(y_p) for y_p in predictions]\n",
    "        Y_test_class = [np.argmax(y_t) for y_t in test_labels]\n",
    "\n",
    "        loss = 1 - f1_score(Y_test_class, Y_pred_class, average='weighted')\n",
    "        r2 = rsquare(Y_test_class, Y_pred_class)\n",
    "        \n",
    "        # Change the seed between instances\n",
    "        variable_seed += 1\n",
    "        \n",
    "        losses.append(loss)\n",
    "        r2s.append(r2)\n",
    "\n",
    "    # Return a dictionnary of metrics. The 'loss' key is mandatory when\n",
    "    # using hyperopt.\n",
    "    return {'loss': np.mean(losses),\n",
    "            'r2': np.mean(r2s),\n",
    "            'f1_score': f1_score(Y_test_class, Y_pred_class, average='weighted'),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_config = {\n",
    "    \"exp\": f\"hyperopt-odontoceti-3\",     # the experimentation name\n",
    "    \"hp_max_evals\": 200,                # the number of differents sets of parameters hyperopt has to try\n",
    "    \"hp_method\": \"random\",              # the method used by hyperopt to chose those sets (see below)\n",
    "    \"seed\": 42,                         # the random state seed, to ensure reproducibility\n",
    "    \"instances_per_trial\": 3,           # how many random ESN will be tried with each sets of parameters\n",
    "    \"hp_space\": {                       # what are the ranges of parameters explored\n",
    "        \"N\": [\"choice\", 1000],           # the number of neurons is fixed to 500\n",
    "        \"sr\": [\"loguniform\", 1e-3, 1e-1], # the spectral radius \n",
    "        \"lr\": [\"loguniform\", 1e-2, 1],      # idem with the leaking rate, from 1e-3 to 1\n",
    "        \"iss\": [\"uniform\", 0.4, 0.9],         # the input scaling \n",
    "        \"ridge\": [\"loguniform\", 1e-4, 1e-1],  # regularization .\n",
    "        \"seed\": [\"choice\", 1234]        # an other random seed for the ESN initialization\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "# we precautionously save the configuration in a JSON file\n",
    "# each file will begin with a number corresponding to the current experimentation run number.\n",
    "with open(f\"{hyperopt_config['exp']}.config.json\", \"w+\") as f:\n",
    "    json.dump(hyperopt_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.hyper import research\n",
    "\n",
    "best = research(objective, dataset, f\"{hyperopt_config['exp']}.config.json\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
