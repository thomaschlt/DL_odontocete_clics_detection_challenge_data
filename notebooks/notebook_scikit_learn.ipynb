{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div align=\"center\" >\n",
    "\n",
    "![Confusion Matrix](../images/ENSC.png)\n",
    "\n",
    "# <u> ENSC Parcours IA </u>\n",
    "## Data Challenge - Détection de clics d'odontocètes\n",
    "\n",
    "</div>\n",
    "\n",
    "As part of the [Artificial Intelligence specialization](https://3aia.notion.site/3aia/Parcours-3A-IA-2023-9917027c682b457dae71fea68c067ad1) at the [ENSC](https://ensc.bordeaux-inp.fr/fr), we participated in a data challenge provided by the University of Toulon in the [ChallengeData](https://challengedata.ens.fr/) website. \n",
    "\n",
    "This challenge specifically aims to detect the presence of odontoceti clicks in underwater audio recordings in the Caribbean sea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature as feat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import soundfile\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### There are **_23168_** audio files in the dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "Here is the split into good and bad signals:\n",
       "| Label   | Count   |\n",
       "|:-------:|:-------:|\n",
       "| 0       | 13718 |\n",
       "| 1       | 9450 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the path to the downloaded data\n",
    "download_path = Path.cwd() / \".dataset\"\n",
    "\n",
    "# Read labels file\n",
    "labels_file = download_path / \"Y_train_ofTdMHi.csv\"\n",
    "df = pd.read_csv(labels_file)\n",
    "\n",
    "# Construct file path by concatenating folder and file name\n",
    "df[\"relative_path\"] = str(download_path) + \"/X_train/\" + df[\"id\"]\n",
    "\n",
    "# Drop id column (replaced it with relative_path)\n",
    "df.drop(columns=[\"id\"], inplace=True)\n",
    "\n",
    "df.rename(columns={\"pos_label\": \"label\"}, inplace=True)\n",
    "\n",
    "# invert relative_path and label columns positions\n",
    "df = df[[\"relative_path\", \"label\"]]\n",
    "display(ipd.Markdown(f\"### There are **_{len(df)}_** audio files in the dataset.\"))\n",
    "\n",
    "table = f\"\"\"\n",
    "Here is the split into good and bad signals:\n",
    "| Label   | Count   |\n",
    "|:-------:|:-------:|\n",
    "| 0       | {df['label'].value_counts()[0]} |\n",
    "| 1       | {df['label'].value_counts()[1]} |\"\"\"\n",
    "display(ipd.Markdown(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take one file to check mfcc with librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio data shape: (51200,), Sample rate: 256000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGzCAYAAADHdKgcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnk0lEQVR4nO3deVhUZfsH8O+wDIsKuLCIoqKiiAsmKEKmpiQqVvwyU19T8zXNMl9Ns9QMLC3MLTNNsjLbzKXFSg1F3EoRE9Hcl8QgacCNRZR1zu8P5DiHWZiBGWZgvp/rmks555kzzzkMc+55lvuRCYIggIiIiMiK2Ji7AkRERES1jQEQERERWR0GQERERGR1GAARERGR1WEARERERFaHARARERFZHQZAREREZHUYABEREZHVYQBEREREVocBEBHRfV999RX8/f1hb28PNzc3c1eHiEyIARARGdWWLVsgk8nw448/qu0LDAyETCbDvn371Pa1atUKYWFhtVFFjc6fP4/nnnsO7dq1wyeffIJ169aZrS5EZHoMgIjIqPr06QMA+P333yXb8/LycPr0adjZ2eHQoUOSfRkZGcjIyBCfaw779++HUqnEBx98gOeeew7PPPOM2epCRKbHAIiIjMrb2xu+vr5qAVBSUhIEQcCIESPU9lX8bM4AKDs7GwCM2vV19+5dox2LiIyLARARGV2fPn2QmpqKe/fuidsOHTqEzp07Y8iQIThy5AiUSqVkn0wmw8MPP4zPP/8cAwYMgIeHBxwcHBAQEIC1a9dKjj9s2DC0bdtW42uHhoYiODhYsu3rr79GUFAQnJyc0KRJE4waNQoZGRni/jZt2iAmJgYA4O7uDplMhgULFoj7P/roI3Tu3BkODg7w9vbG1KlTkZOTI3mN/v37o0uXLkhJSUHfvn3h7OyMefPm4erVq5DJZFi2bBnWrFmDtm3bwtnZGYMGDUJGRgYEQcDChQvRsmVLODk54cknn8StW7cMut5EZDgGQERkdH369EFJSQmSk5PFbYcOHUJYWBjCwsKQm5uL06dPS/b5+/ujadOmWLt2LVq3bo158+Zh+fLl8PHxwUsvvYQ1a9aI5UeOHIm0tDT88ccfktf9+++/ceTIEYwaNUrc9s4772DcuHHw8/PDihUrMGPGDCQmJqJv375iELNy5Ur83//9HwBg7dq1+Oqrr/DUU08BABYsWICpU6fC29sby5cvx/Dhw/Hxxx9j0KBBKCkpkbz+zZs3MWTIEHTv3h0rV67Eo48+Ku775ptv8NFHH2HatGmYNWsWDhw4gGeeeQbz589HfHw8Xn/9dUyePBm//PILXn311Rr+BoioSgIRkZGdOXNGACAsXLhQEARBKCkpERo0aCB88cUXgiAIgqenp7BmzRpBEAQhLy9PsLW1FSZNmiQIgiDcvXtX7XgRERFC27ZtxZ9zc3MFBwcHYdasWZJyS5YsEWQymfD3338LgiAIV69eFWxtbYV33nlHUu7UqVOCnZ2dZHtMTIwAQLh+/bq4LTs7W5DL5cKgQYOEsrIycfvq1asFAML69evFbf369RMACHFxcZLXSktLEwAI7u7uQk5Ojrh97ty5AgAhMDBQKCkpEbePHj1akMvlQmFhofqFJSKjYQsQERldp06d0LRpU3Fsz8mTJ1FQUCDO8goLCxMHQiclJaGsrEwc/+Pk5CQeJzc3Fzdu3EC/fv1w5coV5ObmAgBcXFwwZMgQbNmyBYIgiOU3b96M3r17o1WrVgCAH374AUqlEs888wxu3LghPry8vODn56dxNpqqPXv2oLi4GDNmzICNzYOPy0mTJsHFxQU7duyQlHdwcMCECRM0HmvEiBFwdXUVfw4JCQEAPPvss7Czs5NsLy4uxrVr13TWjYhqhgEQERmdTCZDWFiYONbn0KFD8PDwQPv27QFIA6CKfysCoEOHDiE8PBwNGjSAm5sb3N3dMW/ePAAQAyCgvBssIyMDSUlJAIC//voLKSkpGDlypFjm0qVLEAQBfn5+cHd3lzzOnTsnDnzW5u+//wYAdOzYUbJdLpejbdu24v4KLVq0gFwu13isiqCsQkUw5OPjo3H77du3ddaNiGrGruoiRESG69OnD3755RecOnVKHP9TISwsDLNnz8a1a9fw+++/w9vbG23btsVff/2FgQMHwt/fHytWrICPjw/kcjl27tyJ999/XzJw+vHHH4ezszO2bNmCsLAwbNmyBTY2NhgxYoRYRqlUQiaT4ddff4Wtra1aHRs2bGjUc1ZtvapM0+vr2q7askVExscAiIhMQjUf0KFDhzBjxgxxX1BQEBwcHLB//34kJydj6NChAIBffvkFRUVF+PnnnyUtJpq6qho0aIBhw4Zh69atWLFiBTZv3oxHHnkE3t7eYpl27dpBEAT4+vqiQ4cOBp9D69atAQAXLlyQzDorLi5GWloawsPDDT4mEVkGdoERkUkEBwfD0dER33zzDa5duyZpAXJwcECPHj2wZs0aFBQUiMFSRWuIautHbm4uPv/8c42vMXLkSGRmZuLTTz/FyZMnJd1fAPDUU0/B1tYWb731llqLiiAIuHnzps5zCA8Ph1wux6pVqyTP/+yzz5Cbm4vIyEg9rgQRWSK2ABGRScjlcvTs2RO//fYbHBwcEBQUJNkfFhaG5cuXA3jQWjRo0CDI5XI8/vjjeOGFF3Dnzh188skn8PDwwL///qv2GkOHDkWjRo3w6quvwtbWFsOHD5fsb9euHRYtWoS5c+fi6tWriIqKQqNGjZCWloYff/wRkydP1jnl3N3dHXPnzsVbb72FwYMH44knnsCFCxfw0UcfoWfPnnj22WdrepmIyEzYAkREJlMR2FR0eal6+OGHAQCNGjVCYGAggPLBxt999x1kMhleffVVxMXFYfLkyZg+fbrG4zs6OuKJJ55Afn4+Hn30UXh4eKiVmTNnDr7//nvY2Njgrbfewquvvoqff/4ZgwYNwhNPPFHlOSxYsACrV69Geno6XnnlFWzZsgWTJ0/G7t27YW9vb9D1ICLLIRM40o6IiIisDFuAiIiIyOowACIiIiKrwwCIiIiIrA4DICIiIrI6DICIiIjI6jAAIiIiIqvDRIhaKJVKZGZmolGjRpDJZOauDhEREelBEATk5+fD29sbNjba23kYAGmRmZmptkozERER1Q0ZGRlo2bKl1v0MgLRo1KgRgPIL6OLiYubaEBERkT7y8vLg4+Mj3se1YQCkRUW3l4uLCwMgIiKiOqaq4SscBE1ERERWhwEQERERWR0GQERERGR1GAARERGR1WEARERERFaHARARERFZHQZAREREZHUYABEREZHVYQBEREREVocBEBEREVkdBkBERERkdRgAERERkdVhAERERHWeIAj4MukqUtNvm7sqVEdwNXgiIqrzdp1RIPqnMwCAq4sjzVwbqgvYAkRERHXe5ew75q4C1TEMgIiIiMjqMAAiIiIiq2PyAGjNmjVo06YNHB0dERISgqNHj+osv3XrVvj7+8PR0RFdu3bFzp07Jft/+OEHDBo0CE2bNoVMJsOJEyck+2/duoVp06ahY8eOcHJyQqtWrfC///0Pubm5xj41IiKyEDKZzNxVoDrGpAHQ5s2bMXPmTMTExOD48eMIDAxEREQEsrOzNZY/fPgwRo8ejYkTJyI1NRVRUVGIiorC6dOnxTIFBQXo06cP3nvvPY3HyMzMRGZmJpYtW4bTp09jw4YNiI+Px8SJE01yjkRERFT3yARBEEx18JCQEPTs2ROrV68GACiVSvj4+GDatGmYM2eOWvmRI0eioKAA27dvF7f17t0b3bt3R1xcnKTs1atX4evri9TUVHTv3l1nPbZu3Ypnn30WBQUFsLPTb+JbXl4eXF1dkZubCxcXF72eQ0RE5rFm32Us3XUBAGeBWTt9798mawEqLi5GSkoKwsPDH7yYjQ3Cw8ORlJSk8TlJSUmS8gAQERGhtby+Ki6CruCnqKgIeXl5kgcR1ZwitxAr91xEdn6huatCRCQyWQB048YNlJWVwdPTU7Ld09MTCoVC43MUCoVB5fWtx8KFCzF58mSd5WJjY+Hq6io+fHx8qv2aRPTAuPXJWLnnEl74KsXcVSEiEtXrWWB5eXmIjIxEQEAAFixYoLPs3LlzkZubKz4yMjJqp5JE9dzFrPL8LKnpOeatCBGRCpNlgm7WrBlsbW2RlZUl2Z6VlQUvLy+Nz/Hy8jKovC75+fkYPHgwGjVqhB9//BH29vY6yzs4OMDBwcHg1yEiIqK6x2QtQHK5HEFBQUhMTBS3KZVKJCYmIjQ0VONzQkNDJeUBICEhQWt5bfLy8jBo0CDI5XL8/PPPcHR0NPwEiIiIqN4y6VpgM2fOxPjx4xEcHIxevXph5cqVKCgowIQJEwAA48aNQ4sWLRAbGwsAmD59Ovr164fly5cjMjISmzZtwrFjx7Bu3TrxmLdu3UJ6ejoyMzMBABculI/69/LygpeXlxj83L17F19//bVkQLO7uztsbW1NecpERERUB5g0ABo5ciSuX7+O6OhoKBQKdO/eHfHx8eJA5/T0dNjYPGiECgsLw8aNGzF//nzMmzcPfn5+2LZtG7p06SKW+fnnn8UACgBGjRoFAIiJicGCBQtw/PhxJCcnAwDat28vqU9aWhratGljqtMlIiKiOsKkeYDqMuYBIjKONnN2iP9nfhYylY/2X8aSeOYBIgvIA0RERERkqRgAERERkdVhAERERHWeDFwMlQzDAIiIiIisDgMgIiIisjoMgIiIiMjqMAAiIiIiq8MAiIiIiKwOAyAiIiKyOgyAiIiozpNxFjwZiAEQERERWR0GQERERGR1GAAREVGdxx4wMhQDICIiIrI6DICIiIjI6jAAIiIiIqvDAIiIiOo8ToMnQzEAIiKiOk8QzF0DqmsYABEREZHVYQBERER1HrvAyFAMgIiIiMjqMAAiIiIiq8MAiIiI6jwZc0GTgRgAERERkdVhAERERERWhwEQERERWR0GQEREVOdxGjwZigEQERHVecwETYZiAEREZAZ/XL2FjFt3zV0NIqtlZ+4KEBFZm9PXcjEiLgkAcHVxpJlrUz+wC4wMxRYgIqJadvKfHHNXgcjqMQAiIiIiq8MAiIiIiKwOAyAiIiKyOgyAiIiIyOowACIiqmU5d0vMXYV6R8ZpYGQgBkBERLVs9d7L5q4CkdUzeQC0Zs0atGnTBo6OjggJCcHRo0d1lt+6dSv8/f3h6OiIrl27YufOnZL9P/zwAwYNGoSmTZtCJpPhxIkTascoLCzE1KlT0bRpUzRs2BDDhw9HVlaWMU+LiKja7pWUmbsKRFbPpAHQ5s2bMXPmTMTExOD48eMIDAxEREQEsrOzNZY/fPgwRo8ejYkTJyI1NRVRUVGIiorC6dOnxTIFBQXo06cP3nvvPa2v+8orr+CXX37B1q1bceDAAWRmZuKpp54y+vkRERFR3WTSAGjFihWYNGkSJkyYgICAAMTFxcHZ2Rnr16/XWP6DDz7A4MGDMXv2bHTq1AkLFy5Ejx49sHr1arHM2LFjER0djfDwcI3HyM3NxWeffYYVK1ZgwIABCAoKwueff47Dhw/jyJEjJjlPIiIiqltMFgAVFxcjJSVFEqjY2NggPDwcSUlJGp+TlJSkFthERERoLa9JSkoKSkpKJMfx9/dHq1atdB6nqKgIeXl5kgcRERHVTyYLgG7cuIGysjJ4enpKtnt6ekKhUGh8jkKhMKi8tmPI5XK4ubkZdJzY2Fi4urqKDx8fH71fk4iIiOoWzgK7b+7cucjNzRUfGRkZ5q4SERHpiZPgyVAmWw2+WbNmsLW1VZt9lZWVBS8vL43P8fLyMqi8tmMUFxcjJydH0gpU1XEcHBzg4OCg9+sQERFR3WWyFiC5XI6goCAkJiaK25RKJRITExEaGqrxOaGhoZLyAJCQkKC1vCZBQUGwt7eXHOfChQtIT0836DhERERUf5msBQgAZs6cifHjxyM4OBi9evXCypUrUVBQgAkTJgAAxo0bhxYtWiA2NhYAMH36dPTr1w/Lly9HZGQkNm3ahGPHjmHdunXiMW/duoX09HRkZmYCKA9ugPKWHy8vL7i6umLixImYOXMmmjRpAhcXF0ybNg2hoaHo3bu3KU+XiIjMhImgyVAmDYBGjhyJ69evIzo6GgqFAt27d0d8fLw40Dk9PR02Ng8aocLCwrBx40bMnz8f8+bNg5+fH7Zt24YuXbqIZX7++WcxgAKAUaNGAQBiYmKwYMECAMD7778PGxsbDB8+HEVFRYiIiMBHH31kylMlIiKiOkQmCIJg7kpYory8PLi6uiI3NxcuLi7mrg5RndVmzg7x/1cXR5qxJpaD18T4Pj+Uhrd+OQuA19Ta6Xv/5iwwIiIisjoMgIiIiMjqMAAiIiIiq8MAiIiIiKwOAyAiIqrzOAueDMUAiIiIiKwOAyAiIiKyOgyAiIiozpMxFTQZiAEQERERWR0GQERERGR1GAAREVGdxx4wMhQDICIiqvO4qiUZigEQEdWajFt3zV0FIiIADICIqBYNXH7A3FUgIgLAAIiIalFxmdLcVaB6imOAyFAMgIiIiMjqMAAiIiIiq8MAiIiI6jz2gJGhGAARERGR1WEARERkxW4XFCP9JtMTkPVhAEREZMUeWpiAvkv3ITPnnrmrUjOcBkYGYgBERET4859cc1eBqFYxACIiorqPa2GQgRgAERERkdVhAERERHUfxwCRgRgAERERkdVhAERERPXKS9+k4ERGjrmroZNSyTFL5sYAiIiI6jzVDrCdpxSIWnPIbHWpyt83C9BjUQI+2HPJ3FWxagyAiIiozrtdUGzuKujtvfjzyLlbgvf3XDR3VawaAyAiIqrzlicwmLBEd4tLUVqmNHc1NGIAREREREaXe7cEAdG7MPiD38xdFY0YABEREZHRHf7rBgDgcvYdM9dEMwZARERWqrjUMrsm6jsZmLPIEjAAIiKyUvsuZJu7CkRmwwCIiMgIBEGw2MGe2jAXjXkI4HW3BAyAiIiMYOIXx9BjYQLyC0vMXRUi0oPJA6A1a9agTZs2cHR0REhICI4ePaqz/NatW+Hv7w9HR0d07doVO3fulOwXBAHR0dFo3rw5nJycEB4ejkuXpMmkLl68iCeffBLNmjWDi4sL+vTpg3379hn93IgAIO1GARb/eh437xSZuypkRnvPZyOvsBR7z9edbiVraof49Lcr2HVGYe5qALCeMUCW/v4yaQC0efNmzJw5EzExMTh+/DgCAwMRERGB7GzNHxCHDx/G6NGjMXHiRKSmpiIqKgpRUVE4ffq0WGbJkiVYtWoV4uLikJycjAYNGiAiIgKFhYVimWHDhqG0tBR79+5FSkoKAgMDMWzYMCgUlvHmp5q5eacIgmA5f1qPf/g74g78hVlbT5q7KlTL8gtLUFhSZtBzikoNK081dzIjB4t2nMMLX6WYuypkQUwaAK1YsQKTJk3ChAkTEBAQgLi4ODg7O2P9+vUay3/wwQcYPHgwZs+ejU6dOmHhwoXo0aMHVq9eDaC89WflypWYP38+nnzySXTr1g1ffvklMjMzsW3bNgDAjRs3cOnSJcyZMwfdunWDn58fFi9ejLt370oCKaqb9pzNQtCiPXj9+z/NXRXRnaJSAMDxv2+buSZUm+4Wl6Lrgt3osTDBoOft+PNfE9WItLmez9ZZUmeyAKi4uBgpKSkIDw9/8GI2NggPD0dSUpLG5yQlJUnKA0BERIRYPi0tDQqFQlLG1dUVISEhYpmmTZuiY8eO+PLLL1FQUIDS0lJ8/PHH8PDwQFBQkNb6FhUVIS8vT/KgB/Rpcaluq4whz1txP9vrlmP/VOu1TMly2qTMy5Ja50zpUlZ5bpO7xYa2ANWtgdJkAtbRA2bxTBYA3bhxA2VlZfD09JRs9/T01NoVpVAodJav+FdXGZlMhj179iA1NRWNGjWCo6MjVqxYgfj4eDRu3FhrfWNjY+Hq6io+fHx8DDvheuzK9TsIeTcR639P01rmUlY+er2biC+Trhp07Ov5RXh48V6s2H2hhrU0j7o268fU9HmvXL1RUIs1qn02srpzd6tovQSA23frzlpaRMZQ72aBCYKAqVOnwsPDA7/99huOHj2KqKgoPP744/j3X+1Nz3PnzkVubq74yMjIqMVaW7YFv5xFdn4R3t5+VmuZN348jev5RYj+6YxBx167/y9k5hZi1d7LVZY9mZGDs/9aVsvcGz+yW1WVPu+V/sv2I60eB0F1KP5BadmD1rofU6+Z9LXiTysQf5rjMAGwudhCmCwAatasGWxtbZGVlSXZnpWVBS8vL43P8fLy0lm+4l9dZfbu3Yvt27dj06ZNePjhh9GjRw989NFHcHJywhdffKG1vg4ODnBxcZE8qJymLo3Nf6RjwudHcbe4/BtkmUqZo2m39D620oDukifXHNK7bPrNuxjz6RH8dum63s+pjs3HLD9QLi1T4qVvUrDu4F8mfy1988ocTbtp4pqYXn27hxnyd2uogqJSTPk6BVO+TkGBSqsT1W+W3htusgBILpcjKCgIiYmJ4jalUonExESEhoZqfE5oaKikPAAkJCSI5X19feHl5SUpk5eXh+TkZLHM3bt3AZSPN1JlY2MDpZLdFdWh+i2xwuvfn8K+C9fx+aGravvSb92t0etdy7mH5CvlN0hFbiGS/jL8ZjljcyoOXb6JsZ/pTrtgDXafzcLOUwq8u/O8uatSZ5SUKbHvQrbOnD5//pOjcXtdmuJcWwn5VGfKGTprrl6qO2+Res3OlAefOXMmxo8fj+DgYPTq1QsrV65EQUEBJkyYAAAYN24cWrRogdjYWADA9OnT0a9fPyxfvhyRkZHYtGkTjh07hnXr1gEoH98zY8YMLFq0CH5+fvD19cWbb74Jb29vREVFASgPoho3bozx48cjOjoaTk5O+OSTT5CWlobIyEhTnm69lXRFewCSd/8GYcyBrw8v3gsA+Gnqw2Krz8ZJIQYdI9sMsz7yCy3zm+2dWvzGre8N9drteyauSc0s330RcQf+Qs82jbF1SpjGMkvjNY9bq6oLrMSCxo1Z+jd0XW7cKcKafZfR3ccNJzJyNJa5XVCMxg3k9a61jozDpAHQyJEjcf36dURHR0OhUKB79+6Ij48XBzGnp6dLWmrCwsKwceNGzJ8/H/PmzYOfnx+2bduGLl26iGVee+01FBQUYPLkycjJyUGfPn0QHx8PR0dHAOVdb/Hx8XjjjTcwYMAAlJSUoHPnzvjpp58QGBhoytMlIzue/mBa+ZErhjXP16VxGKZmrhuuIAiQaflFrNp7GTMHdcTC7WdxMiMH307uDXtbyxmSuOV+1+YfVw1PbVDVW2/D4auGV6geMVYw8tp3f1aZdDIrvxCNG8iN9IpkKEv/HDZpAAQAL7/8Ml5++WWN+/bv36+2bcSIERgxYoTW48lkMrz99tt4++23tZYJDg7Grl27DK4rVd/NAuPPICkseXDj3lVHBk9ezs5He49G5q6GxO4zWVUXqoa/rt9BanoOnnqoBWxs1D/p3vrlLBY80Vnr8789mo7P7s8WSzyXjcFdNI8NrIkdf/6L1k2d0aWFq0HP06dFU9v4tao+9P++WbMuYmOqrZYRbYFwTZy6lmv0Y9YWC48LrIblfOWiOul6XnlXk+qH+h/VHExZ+abzXvyDMSsXsvLVyptzIUdBEPDmNvUZYJY4y8VYLUCVr/fA5Qfw6taT2Hbiwewh1V9hVS0dc3849eDYJuiLOZ5+G1M3HsewD383+Ln6vLUsdR1RQRD0/9uodN25OGrtqHyVed3NgwGQFUm7UYDMHOOOvfhBw9TZ6s6MMrS7oe28nYj5qTwIuZ5fhIsagiRTOXLlFr468neV5Qy55mcyc5Fjglwsxggu/r5ZgB6LErAq8ZLavtT0nBofX9c34nvFZUhNv23wTeLy/USFhjp0+QZy7z0Y/FysJXGhtvFOpmjtMMS49UcxdNVvKKvGTXX3WdO0FpqCPm/rujAgfcOhNAS+vRun63CLljaWPsaMAZCVyL1XgkeX7UfY/QHGpladbzR59wxfRfuLpPIgpOc7ezDo/YP4+2Z5fhljffApcguxcs9FZOcXSrbrM7BY9ZpXJEzst3Qf2szZoTYVODX9NiJX/Y7esYmaDlUj2j6Ejqffxkf7L+t1o1z863nk3C0RM3Ebm66gYdz6ZPzfR4fxTXLVAaeq6s5wGr9eOnPw2N+aWzRVu2hVmfuW+9ulGzivyMcFheFfCPLq2Ur2tTXLrSYW/HIW+YWlmPOD5SzvYy0YAFmJjCqmpiuVgt6zhSpnP95wSD3rb9t5Ow3+AC5VCsi9W7MPYG2zQapr3PpkrNxzCZO/lC6iqCuPjVIpoKCoVHLNNx/LwLWce2JX4awt0oVTD1wsz1ek7aZaE9oCoKc+Oowl8Rew+Y+qW+x0fZNTfd9ULvfHVf26Q3U1mlS0DH57tHZyLqmdajXvoXeLS+tepvBaiBcsvVWgNpg7SKZyDICsVJlSwK4zCrFlY+z6ZHSJ2YV0lbE8KX/f1tgs2/OdPZKfF/yiOevv81/+YVCd9pzLwup96l0sVVENNIzd/XDxfjdK5cDqk980L/VwOfsORnychM4xu/CPylTvS1l3cFtloPj+i9LZK6a8KVT1LfhydtVdRbqO8WPqNfx0QnMW4RFxmtf9Uzt+DQYdaz+mQcW11mXj0XSDni+TyZB7rwQB0bsQsfJg9SphBDXNx2X5qv4F14UuMDIfBkBmVFqmxFu/nMGeWuh3r3wz+Cb5b7zwVQoGvV/+AX3ocnmLxg+p5YuM5twtxvC1hzUOIL2tZyvNrTvq41n+zb2HuT/8ifMK9SUtvkv5p1o5ax5Zss/g55jKthOZSLm/Krxql82Gw1cly3jU5rfgmo6v3HchG7sqzSSrPFapYkmQ6saf3yRXHWSc19CimHu3BPN+PCVec1XVPe/KT9tu4Ort5//NE7Mq/3XdfEt+fH+86gWDK59rbXQZWfrUaLIeDIDMaGvKP/j80FU8/+Ux5BeW4LEVByQznyrLKyxBVl6h1v26VP5g23OuvAUiR0MwU1BUij//Mc2AvGkbU/Ht0QwM/eA3jfuN1c2h6dvvvvPZeHjxXjHLtKn9myv9Xa3d/2ApitoMgAxJUqn6HttyLANt5uzAhM/VW/IW7Tgn+bkicK3uef126Ua1nrdox1lsTE7H8LWHxW3X84tqNJi8qnMoLClTe//+m/ugtW95wkVUzgpQWFKmtRv6dx3nXlqmrPbisfrEGZXP9fXvT2HBz2dU9gsY8+kRvPRNCozFeO/9qs/QUoMtcw+Ury2WPgaLAZAZqd4gB6/8DZey70hukpV1W7AbIe8m4sYdw7McGzIrtndsIsatr/kSEgXFZZixKVWyHldFK4hSKB/4+31K1d9SDfHNkb+1zgabsOEPXMu5h9GfHDHqa2pTeXBxtkrwauxp3+f+zcPG5HSNg8+LtMxiqqD6WVzxHrueX4TXvtM8KDM7vxB/XVfvNvvpxDWNLTH6+vrI3+I1Ky1T4qsjf+Nytu5xZKr1+DLpKs79m4ee7+xB97cTTPbhu+PPf9UW5Q2NlU4uqHx/G/bh73hkyT5Jcs8Kz36WrPW1/vvFMfRfth+/nMw0uJ7Vvceqpi+4cqMAhy7fxM5TihqNZzLN7b7q36+ljjcyZuZ8qj6TJ0Ik7Q5ffvDN71oVU6VVp+KeycxDvw7uVR5fEASUKQXY2doY9Aena0kHQwcpbzuRiW0nMpEWO1TtW8//fXRYy7OqLzntltitp42mYFD1WonlKhVclXgJ/xvop3ddKuffKVU5njEDoJIyJYbcb5Fo4GCLJ7u3gCAIiPn5DJo2cMCZzDy18lVlXdY1Jfc/nyTDWW6rtn36phOGV17F/G2nYWcjw6herfBNcjpiVFoi9BH9k2HlDbHvfDa+SU7Hu091kSz8q43qe12RWyiOs/r5hP6BTGmZEgfvD47fcPgqHg/0NrDWVavqc0H1b6AutlqUcv1H0oEtQGZ0TMu35R2VxhzkFZagw/xfDT7+uPVH0evdRNwtLlW76Vf3G0h+UfVmaZnzC8/qvVUPrJ6w4Q8ELdojGYNUMTOrgqFTwCu3AJVJAiCDDqXVxax8+L8ZL/5cEexczr6DL5P+xvt7pHU+dvUW/N74FWM+lbaClZQpsUllsK+ulpzL2XdM1kV68v5xl+/WvM6WqnP/5iFDx5pixnzPTdjwB/acy8LbWgb8V1ai8oWlOqkN7haXote7xk+JUNlRPWfpmUt+YQmOXLlZ7USBkat+R1o1uxCrS6kUcOTKzXqXUqA+YgBkgaZuPC75eftJaUCkb/Dy26UbuFVQjMRz2VBtLi4qLav2mIvqqmjxMEcgtGz3xSo/jPZfuI7ceyXoErMLV67fwcbkdEzYYNgstspKKwdAlU7+thGWD1m264IksFp38Ap+OP4P3t6u+Ub99P1ZWRWD3is8sfoQ5qhkZv7CzOtV5VWxsGx2XiGGfPAbrutY9NYUb7Xs/CK9uqBVs1xXx+/3/3Yr6Ps3L5kRqUfH085Tlpe5XNXTa5Mwat0RfKNhJp6+nyVr9l2u1S6nTX9kYNS6Ixiuo4W7Lram1UcMgMzgbnEp8g34dlB5LMNzn/+B3WcefHDduFOEqd8cx5zvNY/ZWLPvsqTFYd2BK1pf63YVg0er+4dr7h7vdysN2s25W6x1TMOA5Qcw78ea3cAAqN2cK38Gj/7kCMqUgl6B0M07RRo/xDVl7p255aTBAe65SmNa8mtxBXlV3x5N1zhDsDJ9vtVXXqpEEATcvB+83C4orlam5KNpt7BEyyrwqrStjZeVV1it19Ul/eZdDPvwN/x8MlPyezRGN6vqEZ6OOyx+dhWWlNXgmPrXq2IJnG0aMs7ru/6gIEASTJpaxdIwl/RIL1Gb3os/j7GfJddqbipLT0PAAKiWlZQpERC9C10X7Nb7OZo+xyZ/VT4r49PfriB40R7sOPUvNv2RofHD9WJWvuQYy3V05XyZpDvbrqYPIn2Ye8zf6Uxpl033txPw1NrDOJGRg0OXa7c1rMJ5RT6i1hzCQwsTdCaN3Hs+C0GL9mgdlFxTFdmzLcWUr6qecWRoIP5+wkW8se00ghbtwZp9l/HQwgTJzLHa8quea8VVPr8rNwqwMTkd21KvqQUf/9uUitPX8vC/b1MloUVNlrXQlBsqNT0Hb247g673B8obwhgNHrcLirEt9RruFRsWfH1//B9J66Y12XVGIf4u1+7/C79duoH9F65X8Szj4SwwkqjONxFtzbcHL15Xm46sYVFuyGQyFJVq/9CYvfWk1n2VLd1V9bdfTeZvO4WfqzGTxVhOX1NvVfjzn1xErTmEMZ9qn4VT2ZnMXDyx2vDFNbWpWNE6/oz2G+PKPeVjmLYaecZchYqUCJYiV48lUQy9oX6QeAkb7+caqngPn8jIwbqDf2lc38zS5NzPdzRj8wm1sWiqSTp1fdEoLVPq/XcYvuKAxu0VuYVy75WYpFtJ1zHHfJqMGZtPYOGOs7XWpXX4rxt4detJyeSPujKDK+mvm3jhqxS136WmxZF/TP0HMT+dtrpFWRkA1TJ9Er6pKigqxZtaZrdomqouk8lwq6BYMhagTClg7Gfap7Wb6saqasuxf/C/b1ON3vxf2yJX/W6yAcCGqryeWH2hz1tkRg1nnFV4d+d5rEi4qDbxwJLF69mKBEhv1j+dyMTXR9Lxv29TjVKPnu8kGnUBz5t3itDnvX1Yuks9F5ogCGLqgY3J6ej5jukHiAPlMx6/S/kHgW/vRlFpGTJz7iE0di/W7LussbwgCGrdyeai+rvRFPSoemXzSXyR9Dd2n9X83lLkFkrSeFSHJQZXDIBqmb7fNj/97QqKS5X4QY9srpX1WJhgUdmRVRXXtbWRzKCqddsqDFi+37QVMRN9WoCqShthqMoTD+qLXZXGChpKV2PHjTtFmLH5RDVqpdmS+Au4lnMPa/Zpz4Wm+trV9WPqP2ozPPVx4MJ1LN99EYq8Qq0t4Ut3XdCZRqQ2qbaSJl+5pXF7ZbcK1P/2CkvK0Ds2Eb3eTazR+KGLVeT0MgfmAbJQi3acg1IQDG5tqO0pn2R8j6/+HZ+MC8aYT5Lh6mwvDtytLCuv+jcBsmz69PCdzMjBk2sOVdoqjVi2HvsHg7s0Lz9mNcbhXMupehFlYyhTCth8TJoFPv60aVrlXtlc3uUf1q4p3hwWgE7NXQCU3+jltjawsZFh4fazGltNyqrIK/SRjkS2Fa/hYFc77Q6q48gMHYtTWFIGR/vyXF+qwzaGrz2MJU8HoqNXI72OoxpAyyBDxq27eGTJPrg3csAfb4QbVCdTYAuQBVv/+1WD1yF64atjJqoN1ZacuyUYEZeE4jIlrucXGS1nUH1hqjEYFxT5+PQ37TMkTWnf+WwUlypRUFSKfeezq+yyAKAh+FFvsUk8Xz6+K/duSbVaPeZ8r3vwcHV+EwVF0vGIN+4Uod28nZJtx9NvY8rXpm2VO/zXTXFoQEUKjGc+TkJBUSk++z1NbUJITaeu37xTBP834xG15hAOXNBv3J1SKeDgxetavwTpUp3aChCQcDYL/m/GY91B9WDu5D+5GG/AKgGq74+4A3+JPRPX84uM3opbHWwBsmCKavS5VqxeTvXb+t81r0Zf32XlFaKRo2k+tsy5cnvlnFONne21lk2/dRdxB6ruJlL1dNxhtWnZVc3oXJV4Cdk68iwB+gejqtOhX/w6BfEz+oo/91+6X638U5Vy6BxPz9HrdQxV0ZW2/0I2SpUCjv19W2um75MZOdhWKZP3kSs3sfd8NmY+1kFsMdHmP5+UT7Y4qaVVX9NEjR9Sr+HVrSfRpIEcx998rMrzuXK9PAHqlH7tqixb4XClWbCTviz/Ev3uzvNo3bQBurZwlew35L6k+v74sdL7raSKJXpqA1uAiOqQ/kv3Yfjaw1oTHdZ3hk6/rqtuV7HkzOJfNS+arC0cqRz85BeWVDl+R5/M5xWvl51XKFmup8LtgmIUFJVKumDOV0r5cMfCBvNri+lWaxj4PGrdEaw7eAV93tsLRa72wCD3bomY08gQCfcHJes7e/iptYex4fBVvPhNio4uT+mOw39pXxz6BT1SUqj69LcrGLzyoNhipWuhX0vAAIioDrl6826NFhytD97TcvMnzTQNKjckD5kuggCcV+Sh17uJaukh8gpL8NDCBHRZsEvteZY0GzT+9L+S4E3fuqkuHXPjTrHOJU/ultROkJdzP3A+mZGjowtMen6qWfJr2ru8aMc5nFfki8FibcwwrgkGQERUp3xRRbJOa/ZOpbxgAPCKEWdqVVamFPDT/W6h84p8yaDoi/dbegRBfVmYLfcHPFvC1OgpXx8Xc20B0DtLvyHJFX8yYBFcVaVl1b8+NpqSwt2net1VxzppejV9hz6pHrOwpOrurZe+Oa4x4WZtYgBERFRPaBpYuve86RJdXsu5h30qx9f2WhsOXZX8/MaPp3AxKx89FiWYrG6GUL1u/TSMSaquiq6ro2n6LTpbeRB+Yg1+d6pxS8UiyUD5VP2gRQk49U8uLurRLafPuNLkKzfRVmUg+7dH06ucxXf23zw8a0ASWlNgAERERNWmOqYn914J/vwnB2v2XZbk/Ko8fkYpAIPePyh22dRX3xwpb13RNwhdtOMcfruke7aeIAhY/3uaQUv4qI4Z++t6AW7fLcHjq3/HoPcrDfzX0AcW/dNptW3Z+YVYueci/s29h4xbdzFy3RG1MvrM4qvORB9j4iwwIiIymidWl0/PHxTgaeaamF/SlZv45U/Dur/GfnYUVxdHat1/+K+b4iQIbeWUAqqV+OndnZqycKuXe/Hr40j5+zZ2/PkvZoR3MPh1LAUDICIiMoqrKgvr1mQx1vpC1wyr6vrntn6Z4qszovleifqakUoNx6mYiGFpK94bil1gRERkFB/u1bxGFtW+74w0A6uqOKouLyPDAIiIiMjCZFYa0J6db9h4GW0JFw1lCRmbTYUBEBERkQXJuHUXYYv3SrZ9mMjWNWNjAERERGRBNK3bVnp/IVZZpRSHW45lYOo3x1FUqj5+h3TjIGgiIiILMn+b+tRzTWNxrly/g9e++xMA0LNNY1NXq95hCxBZtHf+r4u5q0BEZHbX7y9MqzqtfsDyA+L/F/xinesD1gQDILJYh+YMwODOXuauBhGR2SWez8a6g3/hNwtfYLQuYQBEFs1Wx3o2RETWRFOiwrouT8+110yBARBZNDdnOZ4OamnuahARkQn8mWGc6frVwQCILJZwf9TfshGBeKpHCzPXhoiIjK2krOqV402FAVAtmzagvbmrUGc0d3US/x/7VFcz1oSIiEyhXgdAa9asQZs2beDo6IiQkBAcPXpUZ/mtW7fC398fjo6O6Nq1K3bu3CnZLwgCoqOj0bx5czg5OSE8PByXLl1SO86OHTsQEhICJycnNG7cGFFRUcY8rWrz93IxdxXqhHlD/SXjfxzsbM1YGwIATxcHjdtfG9yxlmtCRPVFqdLwNcuMxaQB0ObNmzFz5kzExMTg+PHjCAwMREREBLKzszWWP3z4MEaPHo2JEyciNTUVUVFRiIqKwunTD3IiLFmyBKtWrUJcXBySk5PRoEEDREREoLDwQZrw77//HmPHjsWECRNw8uRJHDp0CP/5z39Meap6K6vGAnXWqHKyLzK9lo2d1La1buos/n/DhF54+8nOamUaOdqbtF5ERKZg0gBoxYoVmDRpEiZMmICAgADExcXB2dkZ69ev11j+gw8+wODBgzF79mx06tQJCxcuRI8ePbB69WoA5a0/K1euxPz58/Hkk0+iW7du+PLLL5GZmYlt27YBAEpLSzF9+nQsXboUU6ZMQYcOHRAQEIBnnnnGlKeqtybOcnNXoU7w0NLaUNveG249XW+fje+ptm35iEDx/00byDEutI1aGYFBPRFVkzm/6posACouLkZKSgrCw8MfvJiNDcLDw5GUlKTxOUlJSZLyABARESGWT0tLg0KhkJRxdXVFSEiIWOb48eO4du0abGxs8NBDD6F58+YYMmSIpBVJk6KiIuTl5UkepvBw+6YmOW59M6ybt7mrALmtDUzRPf3VxF7GP6gRNHBQ72b0cnVU2+beSBqcKs3YhE1EdZvMjBGQyQKgGzduoKysDJ6enpLtnp6eUCgUGp+jUCh0lq/4V1eZK1euAAAWLFiA+fPnY/v27WjcuDH69++PW7duaa1vbGwsXF1dxYePj48BZ6s/mUymdgMxN3tb83c3NXJ4sCqLb7MGOvP/dPdxq4UaAQIEONrX/E/kicAHwZxMZpm5jTZM6KmxK0t1m839entUev8O7drctJUjIjKBejcLTHl/wbg33ngDw4cPR1BQED7//HPIZDJs3bpV6/Pmzp2L3Nxc8ZGRkWGyOpZZ2Dfm76aE4cq7Q3H27Qiz1cFGJSgIbq17TZvamhIvCOUtUQP8Pap9DGe5LR71dxd/7tO+GWxq4StP3w7u6NHKTa+y84b6o39HD7g62WNUzweB/9F5A+HqZI+xvVtjdK9WaNZQc+Du4aLeSgSUpy8gItLNfF8ITRYANWvWDLa2tsjKypJsz8rKgpeX5uUNvLy8dJav+FdXmebNy7+NBgQEiPsdHBzQtm1bpKena62vg4MDXFxcJA9TmdjHV22buRay82jkgEAfN9jYyOAsN8/auD5NnKDaKBL9eID2wihPjqhq5mMdMC60tfhz5YG6q0Y/VK16vdi/HeR2Nlj/XE/MjtA908nN2R6vDe6Inf97RLJ92gA/yc+tmzrXSgDUQG6Lj8cGY+ZjHaouq9L6tnh4N1xdHImriyPFwGZhVJcq0xB8Mi4YbwztJNnGBJZEZMlMFgDJ5XIEBQUhMTFR3KZUKpGYmIjQ0FCNzwkNDZWUB4CEhASxvK+vL7y8vCRl8vLykJycLJYJCgqCg4MDLly4IJYpKSnB1atX0bp1a1iCF/u1w09TH5Zs2zolzCx1qXxjmx/ZCU0ayBFURSuMIUZUcSMMbt0En4wLhpuzPZaPCDR4VtH/BvrhlfAO8HJxxISH26gN1H0i0NvgrqzPJ/TEjPAHwUPF70y1VaVnm8ZY8nQ3uDnbY/1zPfFS//YI8JYGzi/0bSv5ub17Q6193p+OCzaojrrIZOVjdf430K/qwgbSNOb5sQBPPP+IemC/UMOsMSKiCuacRGHSLrCZM2fik08+wRdffIFz587hxRdfREFBASZMmAAAGDduHObOnSuWnz59OuLj47F8+XKcP38eCxYswLFjx/Dyyy8DKB8/M2PGDCxatAg///wzTp06hXHjxsHb21vM8+Pi4oIpU6YgJiYGu3fvxoULF/Diiy8CAEaMGGHK09WbjY0MgT5uiKxi7IS/VyOjv/ahOQMkP9vZSt8Czz/SFinzwyUtKjWRFjsUS6voCrG1kSG4TROkvvkYhlez1aBxAzmS5g5AzOOab7iPBRi2qGpv36aSsToVvzO53YPrteWFUDwT7IPUNx9Dj1aaA0abSuN9Roe0kjT4bpwUgicCvXFsfjjCAx6MbVN9HX31ad9M/H+Ib+0PtpfJZGjhJp1KP1bDrDFr0N6jIVo1ca66IBGZjUn7PEaOHInr168jOjoaCoUC3bt3R3x8vDiIOT09HTY2Dz7ow8LCsHHjRsyfPx/z5s2Dn58ftm3bhi5duohlXnvtNRQUFGDy5MnIyclBnz59EB8fD0fHB+MQli5dCjs7O4wdOxb37t1DSEgI9u7di8aNzdPNpM2q0Q+hqFSJkT3VB1wvebobBvp7YERcEq7cKDDaa1Ye8BzY0lWtjEwm0/gtvzpk95s72ro3wJXrms9jdK9WkrJVEQQB7dwb4K9Kx9P1/NcHd8QvJzP1Oj4AOMk1J15UvS4Vr6ftdX2aqOfVcbCzRcf7ga2tjQxh7ZohrN2DwGXrlFCs3nsZH/7nIXRbsFvv+gLAgicC4GBniz+u3pIMvFYlt7PBkuHd0K2lKwYsPwAAsLcxLNj638D2mPL1cbg52+Oz8dJWq1cjOuCVzScxupdpJhFUZmcjM2oitRZuTriWc6/Gx1k/vif+unEHEz7/wwi1Iqq/zDki1uSDPl5++WWxBaey/fv3q20bMWKEzpYamUyGt99+G2+//bbWMvb29li2bBmWLVtmcH1rk62NDJ+O19zt8Uxw+Q0kfkZf5BWWIHjRHq3HSXilLx57/6D48+m3IqAUBMz5/k/sPCWdcefe0AGRXZujuEyJJcO7qY2nMZX46X3x0Nu7UVBcJtne3cetWt1thgZomsY39evgjveGd8O6g1ew/lCawXWoSkUdPRtJBwk3crTHyehBsLdTD5x6tmmCL/5r+DT5ri1c0c69IWQyGXx0tDw85OOGqIfKB5FPG9Aehy7fwBPdDUs5MLhLcxyZOxAejRzUWrj+76GWCG3bTGvWaFWbJ/fGyHVHDHrtyl4e0B4r96hngq8uXTP0dr/SF95uTugSs0tt31tPdEbMz2cAAFP6tUOrps7Ivae+ynUjRzvkF5Yarb6kv7hngzDl6xRzV4MqUdbXLjCqObmdDZo1dJAM7K08sLXyDa+hgx1cHO3x0ZggtePJZDKsGdMDn4wLRuMG2oOfLi1qNgh8RrifpHVAbmeDKf3aAQACVaax11ZKAFuVVppvng/B8318sfyZQHi5OmLWoA54oW9bvPt/VSc9HHa/ZUVT605lfTuUz/4KbdcUsx7rgI/HPvh9uDrbG3XQ+WfPBevVgvbhfx4MCJ81qCN+eOlhONobvsyIl6ujWvCjuk+fuoS0bYqFUV2qLKeqsbN0fFj/jg9m6M3SY8B3eCcPNFfJbdRAbiuZgKDr/djBsxEaOthh5cjuavtUT7dZw/K/q64tXTFniD9Wq1zzmnRrt3VvUO3nUnlrIVkec+ZRZQBkQRo5ar8hqk7F/m8fX3ipTD12tLeVLFmganE1FxFt76H9g7qNltdSNSO8AwZ2kuZrerF/O3z53174WiURYHU+kpzldgY3m8pU3ult3Rtg/rAAcVp3Awc7zB3aCf8JaYXvpoSqjZNSNaZXK3w1sRd+eblPla854P7NWSaTYdpAP0R0NmwcUlWWDO8m/t9Oz24sj0aap6zXtorB2ZFdmxuUFylxVn/Je9rfqxG+fzEUv7/+KKZVGvA9UEP6godaNcaWFx5MwpDb2UjGjbno+Bus0N6jodq2BlqC2Sn92kmSejZtUP2Af/PkUDyvMoO0un/b9ZUhX6b+x0WpLYY5u8AYAFmQfvdbDJpryL5bmVulb8J+WgKWUb1a4f8eql7enCvvDsXFRUPUtu+Z2a9ax7OztUHfDu7VXjvqjaGdMKxbcwzw9zB45oCDyqBiZ3vtN7ngNk3UBvKqsrGR4RE/91rrOqzQoNKYpLVjeuCZnj54vo8vJjzcBk10tOZZom4tyseeNWkgx9m3I/CJlhlwlVs7mzSQ42GVwd4AENS6CVo2Vg/KZw7S3CKk+kVDJpOhs7cLngluiekD/fQKxpo2VL/WVXUjfjouGP06uOOtJzujU/Pqta42cLDFzEEdEN7JA0ue7oZRvVohvFN5kKdpHTcAVU60qE/ktrpvZ6qtdFP6tzNxbUhfAdX8ezAGBkAW5N2nuuKNoZ3w/YvGnRJf1QeDNjY2Mo2zkTTdJEJ8mxh07G73B1+PCNZ/sOykvm2x+j89YGsjq/JbQ+UeGAc7W3w2Phhrx/SAq3PdWrzz0Y7uOPP2YMm2IfdvbPOHBWid+VbBXDmm9OVgZ4vHAjw17hvYqXpJKDt7u+jVtP5cWBvIZDIseToQrzzWASN7ttJYbs/MvuL/m7s64cPRD0nGOdnb2ojZzCu6PlWFB3jii//2gqeGpJFNtQSvj/hJAz25rQ2c5Xb4dHxPcYzg8me6442hnbB1Sihe6NdW7RiaUhNYq64tHkz4cJbb4XEtEwXIcG8OC8DVxZHVeq45VyJgAGRBXBztMalvW3hraIFQHadhK5PVSjI9bTSN72jv0RC92+ofBG15IRR7ZvbVeuOrSjt39W4IVZquzsBOnmLgUBtq2rQb83gAvFwcEV1FgFMVl3q2WruDSk6nym/FipxT378YhoYOVXdnPVMpANf0fmwgt1XrEn480Ftssa2QNG8gDszujw6eusf5VP7+4Oep+b3cu+2DVAa7X+mrlrICAFydyj8zmrs64fUIf3xYzaSflm58NdNyqI778XBxxO+vP4qT0YMAAO8/E4hdM/pqe2qNxD2rPv6yPguv5hcVgGOASA/NGjpgdkRHvDG0E5zktjBk5rJQw1tx5W+iml/DMI726jcVQywe3hUjglpiW6WEkhXMGSBWqGmCrwkP+yJp7gD4NpMOfo0ycNZWba2dZgqaxix5NHLE7IiOmB/ZCQ520q7BpSMCkRY7FI72tmjTrAFmhKsngpSmMqi6Dk/q2YXc0MEOrZtWPVC5cqvqypHSoGXtmB4Y27u1JJO2tlYiVTY2MjHFQgVNX6bqoree7IK02KHizy/0bQu/SmOxNP0uK7e4tWzsLLYA29naqF0vY0iLHYrBXR6M92vSQI6X+rfT+F6sLzR92aj8+9GGY4BIL1MfbY9J9zMLz3qsfGmGkQZ0IVXX3CGdqi5UyzwaOWLpiECtN3ddM9zqEk2tbeEGtppZQCyoF9XAYEq/dvh2Um+tA1unPtoezz+i3uUDSK/ZjPAOODC7v/izo72tJDjWJ1COHqZ7aZaa8nJ1xHNhbcSfh3RtjoVRXSStF9W9SXi6OGLjpJCaVVCHxs72iHu2h1GzmGuj+nt1ktvq9b7WJ/jf/2r/6ldKg4p6HpjdH3HPBiFlfjheG+wvySxvaSov4VPZ2jE99DpOxdCG1wf7Y/MLmld8qMycH08MgOqoR/09kPrmY1g8vHwmSEBz43+TqRDg7YKIztKb7rapD6NdpWm5nb3Vkyqay4YJPdG1hSu+nmi6D/+6wpxNzIZQ/SCcM8Qfoe2Mk826ddMGmPpoO/Rs0xj/6dUKrs72GBHUEk/1aFHlzKGng1pWK02ALpp+H5q+QasGZzXJlRLWrhm+m6LfzcgQx998DKnRgzC4S3PJuLrKA7KT5mqfVVmVhU92xpV3H7T8RA8LQHDrxhrXU9TExanq7t9mJkrF0bppAwzu4qV3glcAWFDFOoimEuDtgvXPlQexTva2at27nlVMzKn48vLjSw/jZPQgvNi/nd4TM7TNYK4N5ln9koxCtZXjpUfbQyaTIbyTeuuAzAgx9sdjg/HF4avwuv+H0N3HDYmz+qPNnB33XwOYNagDGshtEdHFuNO9q6Oztyt+mVb1VHVTspS4w1LqUVP6rm6vyewIf8nPVS3PUqGLt/lmqEjumzX8JZriy4nqDU41Pvt2Um8s3XUBP9/PvO7ZyBFtmjrj6s27YpnoYQF4e/vZKl+jddMGknxT/+3ji//qGfwAQDXnf5jMb689ikeW7NO6X1tuLWN6uH1THLp8E0B5N9X0+11zA/w9xYHMEzdIM5i31pFcdZnK+o22NjKDJ5kYEiAam4W9Pai6HO1t8cpjHdBVw9IWxjI+rI3OXDbOcjvMHNTRolqC6iNjBLTm5uyg3qqyblww7GxkeG+45vw2tZ16ANDdgvDyo35wtLeR5OapLk1dtq5O9ujs7QJ/r0ZizipDqK5F5iS3ReKsftj3an+1MWXG4KySpsGniTMmqywCLJMBC56QDuRX7fKrLn0axWz1uLnqU8ZYdGVpB6TpOmrC0d4GEx5uo3HfR/95MED7hUp5qiq8PsQfcjsbPNWjBXa/0hdNK73/Nk/uDTsbGRY8HiAZq1bZAA25uCwJW4CsQE0HQVP1WErXk6XUo8LIYB+EtlXv3urXwR3nFw7WONsJMM9YAW1rqgFAq6bOOL0gQmt9tWnZ2AknMnIk28aEtMLx9Nti8kyg/JtxRcLN6rQMTK+UGLJi5uRn44Px7s7zeHlAe0StOaTxuVP6tUPcgb/0fq3O3i54tncrcdC1avedTCaDfaVrVBstHcD9rPNJf+ss4yS3xbQB7XE9vwib/sgw6Ph9O7jj4MXrNaih1KNGChj2vdofnx+6qnmnrDyJZtKVm3hSy4SKDp6NcPYt7e/tkLZNdf6tVjDnSu/6YABENRLQ3AVn/83DUz2ql2yxPjPVZ3xdz+j/3tPdtO4zNJgwtarqU536lict/VeyzdHeFmv+oz7QtCaBgrbWq7buDbWuQVghwNsFB2c/ir5LtXfXqJLJZFgUZXmZqaO6t0BxqRI9qlhvcNag8kklgzp7wt7WBmM/O6qz/LBuzbH6Pz2Qe68EP524huifyteB05aQUl8ejRzxdFBLfJfyT42O09zVSecXhlG9WmFUL805ryqY4r1f2UM16NY2BgZAVCPbpj6M7PxCjZl4rdXY3q3x57VcyTpVxjA+tDVOZOSoLTFSFbYAVk8HLfl5LJlkin8NjiNDeQtX0twBcHOS4+m4wziTmVej41X2WIAnEs5mAdA+Nqam71wbG1mVN3pVA/y1/23NjuiI8WFtcPNOkfh55+pkj3GhbcQAyBjpN8I7edY4AAKg8aJHdPaEqx4Dw2vDgdn94WPm+4Zlfd0ikzDlmBG5nQ2Dn0oWRnXBT1Mf1phFuybeerILfnq5j8HHtfBWaItTseioprERdUlN7sUVz23u6gQnuS3WjQvGmJBWGN5D+3gPVV6VZg2pvgUrMt0vfqornu3dCtun9dE6NqatjvFKqr+fJTpaFatj1eiH8PKj0vXC3Bs5iLmeKmfDr1jeRFuXkqrvX6z5jDxNv4cX+krTQvT2Ve9m/nis6dMVaFM5mWXlAe7mwBYgIiIVP7wYhj+u3kb/jupLWlirFm5OeOf/umLtfv3GBTVpIMcPL4XBSUMKgaD73VFNGzpo7TbbM7Mvbt8t0Tlo+KVH2yHA2wXBrRujcQM5ViVe0qtu+ngi0BsIBFbvu6xX+U2TeiM57aZerb5BrZugU3MXnPu3+i1qLk7qt+65QzuhXwd3cRxW/47u2DChJzp4NkLGrbtqA5lrg7PKIsFvPdkFX1QxHqu2MQCyAuwCofqgtibruDnLq71Eiz5q6zxM8TqGHLNHqwfjbgytij5Z4u1tbSS/J1NfV12Hd3W2xyAdM2R1+XRcMJ7/8pjGfWffjoBSKF+O5W5xGX49rcAPx//B9IF++POfXKT8fRsA8ONL5a1qYSoLBctkMjEgM1dG8KiHWmDHqQfj3Ro72+P23RKz1EUTBkBE9RzDX8tSW43+puj6rOsD8C2F6mW007EYqGoLSgMHOzwd1FKcdv7N8yH47Pc0DPD3ELvgLE1gpbQsTRrIGQARUS3iICCLYsquCNXW3pq0iGgbzFvd8YR8B0oJWv5vCEd7W0ytNE7J0ni4OGLvrH5o6Fgealja+4CDoImIatGIYP0GEteUKSY/dG5hupaGxgZmEKa6oa17Q42LGlsCtgARUZ1QXxqyKicFNBVTjP0La9cMa/7TA+31XOm7gj6hWD359erFWnsSLe28GQAR1XNMU0CG0hVsRnZrbvjxalAXS2GqNavczTA7i8oxACKq54YHtcTftwrQW8PyE3WJGddMrJPqw5px1qBLC1fMGeKPFmaaqVWbnurREkt3XUAXE3alGoIBEFE9Z2sjU1sNncxrcGcvxJ9RGP24bZsZJ3u1OVJnrHgmEP/dcAzzIzvV+mvrw5Th5JR+7Ux4dMvxQt+26NrCFd3NvARGBQZARES1rGtLV5MEQKpZwmsSxJhjvNUAf09cWDQYDnbqyROtSU3XE7NkdrY26NvBchKMMgCyAlHdW2DLsX/Qzl17Wnkiogrm6m60luBHV+6fLi1csWxEoFV0iZkbAyArENa+GRJn9eMfFBFJVM7M28jRDt6uTgg3cMFdS2DqMU/GDAqXPh2IceuT8Up4B437K5IdkmkxALIS7dzr3srWRFIc1GsIfQKCbi3dcODidfHnj8cGIbRtU5PNeDIlU49b6uBZ9fIc+uro1QhH5g6sk9e5PmEiRCKiekifgEBtvIlguunetc3NyIkVu7RwrbqQAerLda7LGAARUa3578O+5q4Cqai85IWyDifsUW3xCmjugq/+G2K0Y3c1cvBDloFdYERUa6IfDzB3FUhFfV3c9JdpfWBbX0+OjIYtQEREVqpyN0xwm8ZmqollY29V/cQAiIiIsH1aHzja191p6AxSyFAMgIioTuANzrTqepeRavJGY53JYwHl6QCef6StkY5IloRjgIiIrJRPEy6Uq0vcs0G4dvseWjXldaqP2AJERFQP6ZP7a2zv1uL/2cKmztZGxuDnviFdvAAAjwd6m7kmxsMWICKiemTPzH64VVCM1k2rXvpGde2wus4cC7hak+XPBCLqoRbo62c5a3nVVK28+9esWYM2bdrA0dERISEhOHr0qM7yW7duhb+/PxwdHdG1a1fs3LlTsl8QBERHR6N58+ZwcnJCeHg4Ll26pPFYRUVF6N69O2QyGU6cOGGsUyIiskjtPRqil28Tc1ej1pljAVdr4iy3Q0RnLzjJ6+5A+cpMHgBt3rwZM2fORExMDI4fP47AwEBEREQgOztbY/nDhw9j9OjRmDhxIlJTUxEVFYWoqCicPn1aLLNkyRKsWrUKcXFxSE5ORoMGDRAREYHCwkK147322mvw9q4/TXZE1oo9NHWXn6fpl+KRDILmm4X0YPIAaMWKFZg0aRImTJiAgIAAxMXFwdnZGevXr9dY/oMPPsDgwYMxe/ZsdOrUCQsXLkSPHj2wevVqAOWtPytXrsT8+fPx5JNPolu3bvjyyy+RmZmJbdu2SY7166+/Yvfu3Vi2bJmpT5OIiLTwaOSIfa/2x9E3Bpq7KkQikwZAxcXFSElJQXh4+IMXtLFBeHg4kpKSND4nKSlJUh4AIiIixPJpaWlQKBSSMq6urggJCZEcMysrC5MmTcJXX30FZ+eqB7EVFRUhLy9P8iAiIuPwbdYAHo0czV0NIpFJA6AbN26grKwMnp6eku2enp5QKBQan6NQKHSWr/hXVxlBEPDcc89hypQpCA4O1quusbGxcHV1FR8+Pj56PY+IqD5oVcenxKt2e3E8EOmj/kwBUPHhhx8iPz8fc+fO1fs5c+fORW5urvjIyMgwYQ2JiCzD2bcjcDJmEJzldXtScFuVaf82dTypI9UOkwZAzZo1g62tLbKysiTbs7Ky4OXlpfE5Xl5eOstX/KurzN69e5GUlAQHBwfY2dmhffv2AIDg4GCMHz9e4+s6ODjAxcVF8iAi83Nv5AAAGNRZ82cG1Yyz3A6uTvbmrkaNMeQhQ5k0AJLL5QgKCkJiYqK4TalUIjExEaGhoRqfExoaKikPAAkJCWJ5X19feHl5Scrk5eUhOTlZLLNq1SqcPHkSJ06cwIkTJ8Rp9Js3b8Y777xj1HMkItPaPaMvvp4YgqceamHuqpAFY68XGcrkbZ4zZ87E+PHjERwcjF69emHlypUoKCjAhAkTAADjxo1DixYtEBsbCwCYPn06+vXrh+XLlyMyMhKbNm3CsWPHsG7dOgDlqxfPmDEDixYtgp+fH3x9ffHmm2/C29sbUVFRAIBWrVpJ6tCwYXnTaLt27dCyZUtTnzIRGVHjBnL08Wtm7moQUT1j8gBo5MiRuH79OqKjo6FQKNC9e3fEx8eLg5jT09NhY/OgISosLAwbN27E/PnzMW/ePPj5+WHbtm3o0qWLWOa1115DQUEBJk+ejJycHPTp0wfx8fFwdOQMAyIiayRw5DMZSCbwXaNRXl4eXF1dkZuby/FARDXQZs4O8f9XF0easSaWY82+y1i66wIAXhNjGftZMn67dAMAr6m10/f+XS9ngRERERHpwgCIiIiIrA4DICIiqvM4mIMMxQCIiIiIrA4DICIiqvPeiOwEuZ0NZoT7mbsqVEfU7dznREREADo1d8HZtyJgZ8vv9aQfvlOIiKheYPBDhuC7hYiIiKwOAyAiIiKyOgyAiIiIyOowACIiIiKrwwCIiIiIrA4DICIiIrI6DICIiIjI6jAAIiIiIqvDAIiIiIisDgMgIiIisjoMgIiIiMjqMAAiIiIiq8MAiIiIiKwOAyAiIiKyOgyAiIiIyOowACIiIiKrwwCIiIiIrA4DICIiIrI6DICIiIjI6jAAIiIiIqvDAIiIiIisDgMgIiIisjoMgIiIiMjqMAAiIiIiq8MAiIiIiKwOAyAiIiKyOgyAiIiIyOowACIiIiKrwwCIiIiIrA4DICIiIrI6tRIArVmzBm3atIGjoyNCQkJw9OhRneW3bt0Kf39/ODo6omvXrti5c6dkvyAIiI6ORvPmzeHk5ITw8HBcunRJ3H/16lVMnDgRvr6+cHJyQrt27RATE4Pi4mKTnB8RERHVLSYPgDZv3oyZM2ciJiYGx48fR2BgICIiIpCdna2x/OHDhzF69GhMnDgRqampiIqKQlRUFE6fPi2WWbJkCVatWoW4uDgkJyejQYMGiIiIQGFhIQDg/PnzUCqV+Pjjj3HmzBm8//77iIuLw7x580x9ukRERFQHyARBEEz5AiEhIejZsydWr14NAFAqlfDx8cG0adMwZ84ctfIjR45EQUEBtm/fLm7r3bs3unfvjri4OAiCAG9vb8yaNQuvvvoqACA3Nxeenp7YsGEDRo0apbEeS5cuxdq1a3HlyhW96p2XlwdXV1fk5ubCxcXF0NMmovvazNkh/v/q4kgz1sRyrNl3GUt3XQDAa0JkbPrev03aAlRcXIyUlBSEh4c/eEEbG4SHhyMpKUnjc5KSkiTlASAiIkIsn5aWBoVCISnj6uqKkJAQrccEyoOkJk2aaN1fVFSEvLw8yYOIiIjqJ5MGQDdu3EBZWRk8PT0l2z09PaFQKDQ+R6FQ6Cxf8a8hx7x8+TI+/PBDvPDCC1rrGhsbC1dXV/Hh4+Oj++SIiIiozqr3s8CuXbuGwYMHY8SIEZg0aZLWcnPnzkVubq74yMjIqMVaEhERUW0yaQDUrFkz2NraIisrS7I9KysLXl5eGp/j5eWls3zFv/ocMzMzE48++ijCwsKwbt06nXV1cHCAi4uL5EFERET1k0kDILlcjqCgICQmJorblEolEhMTERoaqvE5oaGhkvIAkJCQIJb39fWFl5eXpExeXh6Sk5Mlx7x27Rr69++PoKAgfP7557CxqfeNXURERKQnO1O/wMyZMzF+/HgEBwejV69eWLlyJQoKCjBhwgQAwLhx49CiRQvExsYCAKZPn45+/fph+fLliIyMxKZNm3Ds2DGxBUcmk2HGjBlYtGgR/Pz84OvrizfffBPe3t6IiooC8CD4ad26NZYtW4br16+L9dHW8kRERETWw+QB0MiRI3H9+nVER0dDoVCge/fuiI+PFwcxp6enS1pnwsLCsHHjRsyfPx/z5s2Dn58ftm3bhi5duohlXnvtNRQUFGDy5MnIyclBnz59EB8fD0dHRwDlLUaXL1/G5cuX0bJlS0l9TDzrn4iIiOoAk+cBqquYB4jIOJgHSB3zABGZjkXkASIiIiKyRAyAiIiIyOowACIiIiKrwwCIiIiIrA4DICIiIrI6DICIiIjI6jAAIiIiIqvDAIiIiIisDgMgIiIisjoMgIiIiMjqMAAiIiIiq8MAiIhM6oNR3QEAi5/qat6KEBGpMPlq8ERk3Z7s3gKDu3jBwc7W3FUhIhKxBYiITI7BDxFZGgZAREREZHUYABEREZHVYQBEREREVocBEBEREVkdBkBERERkdRgAERERkdVhAERERERWhwEQERERWR0GQERERGR1GAARERGR1WEARERERFaHARARERFZHQZAREREZHUYABEREZHVYQBEREREVocBEBEREVkdBkBERERkdRgAERERkdVhAERERERWhwEQERERWR0GQERERGR1GAARERGR1amVAGjNmjVo06YNHB0dERISgqNHj+osv3XrVvj7+8PR0RFdu3bFzp07JfsFQUB0dDSaN28OJycnhIeH49KlS5Iyt27dwpgxY+Di4gI3NzdMnDgRd+7cMfq5ERERUd1j8gBo8+bNmDlzJmJiYnD8+HEEBgYiIiIC2dnZGssfPnwYo0ePxsSJE5GamoqoqChERUXh9OnTYpklS5Zg1apViIuLQ3JyMho0aICIiAgUFhaKZcaMGYMzZ84gISEB27dvx8GDBzF58mRTny4RERHVATJBEARTvkBISAh69uyJ1atXAwCUSiV8fHwwbdo0zJkzR638yJEjUVBQgO3bt4vbevfuje7duyMuLg6CIMDb2xuzZs3Cq6++CgDIzc2Fp6cnNmzYgFGjRuHcuXMICAjAH3/8geDgYABAfHw8hg4din/++Qfe3t5V1jsvLw+urq7Izc2Fi4uLMS4FEREAYM2+y1i66wIA4OriSDPXhqh+0ff+bdIWoOLiYqSkpCA8PPzBC9rYIDw8HElJSRqfk5SUJCkPABEREWL5tLQ0KBQKSRlXV1eEhISIZZKSkuDm5iYGPwAQHh4OGxsbJCcna3zdoqIi5OXlSR5ERERUP5k0ALpx4wbKysrg6ekp2e7p6QmFQqHxOQqFQmf5in+rKuPh4SHZb2dnhyZNmmh93djYWLi6uooPHx8fPc+SiIiI6hrOArtv7ty5yM3NFR8ZGRnmrhIRERGZiEkDoGbNmsHW1hZZWVmS7VlZWfDy8tL4HC8vL53lK/6tqkzlQdalpaW4deuW1td1cHCAi4uL5EFERET1k0kDILlcjqCgICQmJorblEolEhMTERoaqvE5oaGhkvIAkJCQIJb39fWFl5eXpExeXh6Sk5PFMqGhocjJyUFKSopYZu/evVAqlQgJCTHa+REREVHdZGfqF5g5cybGjx+P4OBg9OrVCytXrkRBQQEmTJgAABg3bhxatGiB2NhYAMD06dPRr18/LF++HJGRkdi0aROOHTuGdevWAQBkMhlmzJiBRYsWwc/PD76+vnjzzTfh7e2NqKgoAECnTp0wePBgTJo0CXFxcSgpKcHLL7+MUaNG6TUDjIiIiOo3kwdAI0eOxPXr1xEdHQ2FQoHu3bsjPj5eHMScnp4OG5sHDVFhYWHYuHEj5s+fj3nz5sHPzw/btm1Dly5dxDKvvfYaCgoKMHnyZOTk5KBPnz6Ij4+Ho6OjWOabb77Byy+/jIEDB8LGxgbDhw/HqlWrTH26REREVAeYPA9QXcU8QERkKswDRGQ6FpEHiIiIiMgSMQAiIiIiq8MAiIiIiKwOAyAiIiKyOgyAiIiIyOowACIiIiKrwwCIiIiIrA4DICIiIrI6DICIiIjI6jAAIiIiIqvDAIiIiIisDgMgIiIisjoMgIiIiMjqMAAiIiIiq8MAiIiIiKwOAyAiIiKyOgyAiIiIyOowACIiIiKrwwCIiIiIrA4DICIiIrI6DICIiIjI6jAAIiIiIqvDAIiIiIisDgMgIiIisjoMgIiIiMjqMAAiIiIiq8MAiIiIiKwOAyAiIiKyOgyAiIiIyOowACIiIiKrwwCIiIiIrA4DICIiIrI6DICIiIjI6jAAIiIiIqvDAIiIiIisDgMgIiIisjoMgIiIalmn5o3MXQUiq2eyAOjWrVsYM2YMXFxc4ObmhokTJ+LOnTs6n1NYWIipU6eiadOmaNiwIYYPH46srCxJmfT0dERGRsLZ2RkeHh6YPXs2SktLxf0//PADHnvsMbi7u8PFxQWhoaHYtWuXSc6RiKg6Hu3ogaVPd8OO//Uxd1WIrJbJAqAxY8bgzJkzSEhIwPbt23Hw4EFMnjxZ53NeeeUV/PLLL9i6dSsOHDiAzMxMPPXUU+L+srIyREZGori4GIcPH8YXX3yBDRs2IDo6Wixz8OBBPPbYY9i5cydSUlLw6KOP4vHHH0dqaqqpTpWIyCAymQwjgn3Q2dvV3FUhsloyQRAEYx/03LlzCAgIwB9//IHg4GAAQHx8PIYOHYp//vkH3t7eas/Jzc2Fu7s7Nm7ciKeffhoAcP78eXTq1AlJSUno3bs3fv31VwwbNgyZmZnw9PQEAMTFxeH111/H9evXIZfLNdanc+fOGDlypCRQqqyoqAhFRUXiz3l5efDx8UFubi5cXFyqfS2IiIio9uTl5cHV1bXK+7dJWoCSkpLg5uYmBj8AEB4eDhsbGyQnJ2t8TkpKCkpKShAeHi5u8/f3R6tWrZCUlCQet2vXrmLwAwARERHIy8vDmTNnNB5XqVQiPz8fTZo00Vnn2NhYuLq6ig8fHx+9z5eIiIjqFpMEQAqFAh4eHpJtdnZ2aNKkCRQKhdbnyOVyuLm5SbZ7enqKz1EoFJLgp2J/xT5Nli1bhjt37uCZZ57RWee5c+ciNzdXfGRkZOgsT0RERHWXQQHQnDlzIJPJdD7Onz9vqroabOPGjXjrrbewZcsWtYCsMgcHB7i4uEgeREREVD/ZGVJ41qxZeO6553SWadu2Lby8vJCdnS3ZXlpailu3bsHLy0vj87y8vFBcXIycnBxJK1BWVpb4HC8vLxw9elTyvIpZYpWPu2nTJjz//PPYunWrpFuNiIiIyKAAyN3dHe7u7lWWCw0NRU5ODlJSUhAUFAQA2Lt3L5RKJUJCQjQ+JygoCPb29khMTMTw4cMBABcuXEB6ejpCQ0PF477zzjvIzs4WW3QSEhLg4uKCgIAA8Vjffvst/vvf/2LTpk2IjIw05BSJiIjICphkFhgADBkyBFlZWYiLi0NJSQkmTJiA4OBgbNy4EQBw7do1DBw4EF9++SV69eoFAHjxxRexc+dObNiwAS4uLpg2bRoA4PDhwwDKp8F3794d3t7eWLJkCRQKBcaOHYvnn38e7777LoDybq/x48fjgw8+kEyhd3Jygqur/lNO9R1FTkRERJbDrLPAAOCbb76Bv78/Bg4ciKFDh6JPnz5Yt26duL+kpAQXLlzA3bt3xW3vv/8+hg0bhuHDh6Nv377w8vLCDz/8IO63tbXF9u3bYWtri9DQUDz77LMYN24c3n77bbHMunXrUFpaiqlTp6J58+biY/r06aY6VSIiIqpjTNYCVNexBYiIiKjuMXsLEBEREZGlYgBEREREVocBEBEREVkdBkBERERkdQzKA2RNKsaG5+XlmbkmREREpK+K+3ZVc7wYAGmRn58PAFwUlYiIqA7Kz8/Xmf+P0+C1UCqVyMzMRKNGjSCTyYx23Ly8PPj4+CAjI4PT602A19e0eH1Ni9fX9HiNTcsSrq8gCMjPz4e3tzdsbLSP9GELkBY2NjZo2bKlyY7PBVdNi9fXtHh9TYvX1/R4jU3L3NdXn5UfOAiaiIiIrA4DICIiIrI6DIBqmYODA2JiYuDg4GDuqtRLvL6mxetrWry+psdrbFp16fpyEDQRERFZHbYAERERkdVhAERERERWhwEQERERWR0GQERERGR1GAARERGR1WEAVMvWrFmDNm3awNHRESEhITh69Ki5q2R2Bw8exOOPPw5vb2/IZDJs27ZNsl8QBERHR6N58+ZwcnJCeHg4Ll26JClz69YtjBkzBi4uLnBzc8PEiRNx584dSZk///wTjzzyCBwdHeHj44MlS5ao1WXr1q3w9/eHo6Mjunbtip07dxr9fGtbbGwsevbsiUaNGsHDwwNRUVG4cOGCpExhYSGmTp2Kpk2bomHDhhg+fDiysrIkZdLT0xEZGQlnZ2d4eHhg9uzZKC0tlZTZv38/evToAQcHB7Rv3x4bNmxQq099+xtYu3YtunXrJma+DQ0Nxa+//iru57U1nsWLF0Mmk2HGjBniNl7fmlmwYAFkMpnk4e/vL+6v19dXoFqzadMmQS6XC+vXrxfOnDkjTJo0SXBzcxOysrLMXTWz2rlzp/DGG28IP/zwgwBA+PHHHyX7Fy9eLLi6ugrbtm0TTp48KTzxxBOCr6+vcO/ePbHM4MGDhcDAQOHIkSPCb7/9JrRv314YPXq0uD83N1fw9PQUxowZI5w+fVr49ttvBScnJ+Hjjz8Wyxw6dEiwtbUVlixZIpw9e1aYP3++YG9vL5w6dcrk18CUIiIihM8//1w4ffq0cOLECWHo0KFCq1athDt37ohlpkyZIvj4+AiJiYnCsWPHhN69ewthYWHi/tLSUqFLly5CeHi4kJqaKuzcuVNo1qyZMHfuXLHMlStXBGdnZ2HmzJnC2bNnhQ8//FCwtbUV4uPjxTL18W/g559/Fnbs2CFcvHhRuHDhgjBv3jzB3t5eOH36tCAIvLbGcvToUaFNmzZCt27dhOnTp4vbeX1rJiYmRujcubPw77//io/r16+L++vz9WUAVIt69eolTJ06Vfy5rKxM8Pb2FmJjY81YK8tSOQBSKpWCl5eXsHTpUnFbTk6O4ODgIHz77beCIAjC2bNnBQDCH3/8IZb59ddfBZlMJly7dk0QBEH46KOPhMaNGwtFRUVimddff13o2LGj+PMzzzwjREZGSuoTEhIivPDCC0Y9R3PLzs4WAAgHDhwQBKH8etrb2wtbt24Vy5w7d04AICQlJQmCUB6k2tjYCAqFQiyzdu1awcXFRbymr732mtC5c2fJa40cOVKIiIgQf7aWv4HGjRsLn376Ka+tkeTn5wt+fn5CQkKC0K9fPzEA4vWtuZiYGCEwMFDjvvp+fdkFVkuKi4uRkpKC8PBwcZuNjQ3Cw8ORlJRkxppZtrS0NCgUCsl1c3V1RUhIiHjdkpKS4ObmhuDgYLFMeHg4bGxskJycLJbp27cv5HK5WCYiIgIXLlzA7du3xTKqr1NRpr79fnJzcwEATZo0AQCkpKSgpKREcu7+/v5o1aqV5Bp37doVnp6eYpmIiAjk5eXhzJkzYhld188a/gbKysqwadMmFBQUIDQ0lNfWSKZOnYrIyEi1a8DraxyXLl2Ct7c32rZtizFjxiA9PR1A/b++DIBqyY0bN1BWViZ5kwCAp6cnFAqFmWpl+Squja7rplAo4OHhIdlvZ2eHJk2aSMpoOobqa2grU59+P0qlEjNmzMDDDz+MLl26ACg/b7lcDjc3N0nZyte4utcvLy8P9+7dq9d/A6dOnULDhg3h4OCAKVOm4Mcff0RAQACvrRFs2rQJx48fR2xsrNo+Xt+aCwkJwYYNGxAfH4+1a9ciLS0NjzzyCPLz8+v99bUz2ZGJyOJMnToVp0+fxu+//27uqtQrHTt2xIkTJ5Cbm4vvvvsO48ePx4EDB8xdrTovIyMD06dPR0JCAhwdHc1dnXppyJAh4v+7deuGkJAQtG7dGlu2bIGTk5MZa2Z6bAGqJc2aNYOtra3a6PmsrCx4eXmZqVaWr+La6LpuXl5eyM7OluwvLS3FrVu3JGU0HUP1NbSVqS+/n5dffhnbt2/Hvn370LJlS3G7l5cXiouLkZOTIylf+RpX9/q5uLjAycmpXv8NyOVytG/fHkFBQYiNjUVgYCA++OADXtsaSklJQXZ2Nnr06AE7OzvY2dnhwIEDWLVqFezs7ODp6cnra2Rubm7o0KEDLl++XO/fvwyAaolcLkdQUBASExPFbUqlEomJiQgNDTVjzSybr68vvLy8JNctLy8PycnJ4nULDQ1FTk4OUlJSxDJ79+6FUqlESEiIWObgwYMoKSkRyyQkJKBjx45o3LixWEb1dSrK1PXfjyAIePnll/Hjjz9i79698PX1lewPCgqCvb295NwvXLiA9PR0yTU+deqUJNBMSEiAi4sLAgICxDK6rp81/Q0olUoUFRXx2tbQwIEDcerUKZw4cUJ8BAcHY8yYMeL/eX2N686dO/jrr7/QvHnz+v/+NdnwalKzadMmwcHBQdiwYYNw9uxZYfLkyYKbm5tk9Lw1ys/PF1JTU4XU1FQBgLBixQohNTVV+PvvvwVBKJ8G7+bmJvz000/Cn3/+KTz55JMap8E/9NBDQnJysvD7778Lfn5+kmnwOTk5gqenpzB27Fjh9OnTwqZNmwRnZ2e1afB2dnbCsmXLhHPnzgkxMTH1Yhr8iy++KLi6ugr79++XTHW9e/euWGbKlClCq1athL179wrHjh0TQkNDhdDQUHF/xVTXQYMGCSdOnBDi4+MFd3d3jVNdZ8+eLZw7d05Ys2aNxqmu9e1vYM6cOcKBAweEtLQ04c8//xTmzJkjyGQyYffu3YIg8Noam+osMEHg9a2pWbNmCfv37xfS0tKEQ4cOCeHh4UKzZs2E7OxsQRDq9/VlAFTLPvzwQ6FVq1aCXC4XevXqJRw5csTcVTK7ffv2CQDUHuPHjxcEoXwq/Jtvvil4enoKDg4OwsCBA4ULFy5IjnHz5k1h9OjRQsOGDQUXFxdhwoQJQn5+vqTMyZMnhT59+ggODg5CixYthMWLF6vVZcuWLUKHDh0EuVwudO7cWdixY4fJzru2aLq2AITPP/9cLHPv3j3hpZdeEho3biw4OzsL//d//yf8+++/kuNcvXpVGDJkiODk5CQ0a9ZMmDVrllBSUiIps2/fPqF79+6CXC4X2rZtK3mNCvXtb+C///2v0Lp1a0Eulwvu7u7CwIEDxeBHEHhtja1yAMTrWzMjR44UmjdvLsjlcqFFixbCyJEjhcuXL4v76/P1lQmCIJiufYmIiIjI8nAMEBEREVkdBkBERERkdRgAERERkdVhAERERERWhwEQERERWR0GQERERGR1GAARERGR1WEARERERFaHARARERFZHQZAREREZHUYABEREZHV+X+LKW4AY6XxSQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the file and load it\n",
    "file_path = df.loc[0, \"relative_path\"]\n",
    "audio_data, sr = librosa.load(file_path, sr=None)\n",
    "print(f\"Audio data shape: {audio_data.shape}, Sample rate: {sr}\")\n",
    "\n",
    "# Plot the audio signal\n",
    "fig, ax = plt.subplots(nrows=1, sharex=True)\n",
    "plt.plot(audio_data)\n",
    "plt.title('Waveform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tristangclvs/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-5.80592590e+02, -6.18172546e+02, -7.06206238e+02, ...,\n",
       "        -7.06523865e+02, -6.18886719e+02, -5.86460754e+02],\n",
       "       [ 1.06721710e+02,  9.30850372e+01,  3.27370491e+01, ...,\n",
       "         3.11220779e+01,  8.59332275e+01,  1.04781303e+02],\n",
       "       [-3.43419304e+01, -3.15824070e+01, -4.91998596e+01, ...,\n",
       "        -4.22441788e+01, -3.49739075e+01, -3.85120888e+01],\n",
       "       ...,\n",
       "       [-1.67548931e+00,  1.78555739e+00,  7.10839319e+00, ...,\n",
       "         1.10129423e+01,  2.24370122e+00, -1.23915851e+00],\n",
       "       [-5.47950172e+00, -2.53973007e+00,  1.23632467e+00, ...,\n",
       "         1.04649715e+01, -2.40652680e-01, -3.20498276e+00],\n",
       "       [-7.75990438e+00, -6.79572582e+00, -7.50377417e-01, ...,\n",
       "        -3.59400272e+00, -1.12350445e+01, -1.08889484e+01]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)\n",
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioUtil:\n",
    "    \"\"\"Static class for audio processing helper functions.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def open(audio_file: str):\n",
    "        \"\"\"Load an audio file. Return the signal as a tensor and the sample rate\"\"\"\n",
    "        sig, sr = librosa.load(audio_file, sr=256000)\n",
    "        return (sig, sr)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_audio_duration(sig, sr):\n",
    "        \"\"\"Return the duration of an audio signal in seconds\"\"\"\n",
    "        return librosa.get_duration(sig, sr)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mel_spectro_gram(sig: np.array, sr: int, n_mels=32, n_fft=1024):\n",
    "        \"\"\"Generate a Spectrogram\"\"\"\n",
    "        # get mel spectrogram\n",
    "        spec = librosa.feature.melspectrogram(y=sig, sr=sr)\n",
    "        spec = librosa.amplitude_to_db(spec)\n",
    "        return spec\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_mfccs(file_path):\n",
    "        audio_data, sr = librosa.load(file_path, sr=100000)\n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13, n_mels=2048)\n",
    "        mfccs_scaled_features = np.mean(mfccs.T,axis=0)\n",
    "        return mfccs_scaled_features\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_audio_specs_size(spec):\n",
    "        \"\"\"Return the size of a spectrogram image\"\"\"\n",
    "        return spec.shape\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_mel_spectro_gram(spec: np.array, sr: int):\n",
    "        \"\"\"Plot a Spectrogram\"\"\"\n",
    "        # plot mel spectrogram\n",
    "        fig, ax = plt.subplots()\n",
    "        S_dB = librosa.power_to_db(spec, ref=np.max)\n",
    "        img = librosa.display.specshow(S_dB, x_axis='time',\n",
    "                                y_axis='mel', sr=sr,\n",
    "                                ax=ax)\n",
    "        fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "        ax.set(title='Mel-frequency spectrogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrograms(nb_files = len(df)):\n",
    "    audio_util = AudioUtil()\n",
    "    label_files = np.empty(0)\n",
    "    audio_mfccs = []\n",
    "    features_and_labels = []\n",
    "    print(\"Starting mfccs generation...\")\n",
    "    for line_num in tqdm(range(nb_files), unit=\"file\", desc=\"Generating mfccs\"):\n",
    "        file_path = df.loc[line_num, \"relative_path\"]\n",
    "        mfccs = audio_util.extract_mfccs(file_path)\n",
    "        audio_mfccs.append(mfccs)\n",
    "        label_files = np.append(label_files, df.loc[line_num, \"label\"])\n",
    "        features_and_labels.append((mfccs, df.loc[line_num, \"label\"]))\n",
    "    print(\"Mfccs generated !\", end='\\n\\n')\n",
    "\n",
    "    print(\"Saving mfccs...\")\n",
    "    os.mkdir(\"numpy_data\") if not os.path.exists(\"numpy_data\") else None\n",
    "    np.save(os.path.join(\"numpy_data\", \"audio_mfccs.npy\"), audio_mfccs)\n",
    "    np.save(os.path.join(\"numpy_data\", \"label_files.npy\"), label_files)\n",
    "    print(\"Mfccs saved !\")\n",
    "    features_and_labels = pd.DataFrame(features_and_labels, columns=[\"mfccs\", \"label\"])\n",
    "\n",
    "    print(\"Global shape : \", features_and_labels.shape)\n",
    "    print(features_and_labels.head())\n",
    "\n",
    "# save_spectrograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_file):\n",
    "    sig, sr = soundfile.read(audio_file)\n",
    "\n",
    "    sos = signal.butter(6, [5000, 100000], 'bandpass', fs=sr, output='sos')\n",
    "    sig = signal.sosfiltfilt(sos, sig)\n",
    "    rms = feat.rms(y=sig) \n",
    "    sc = feat.spectral_centroid(y=sig, sr=sr)\n",
    "    sb = feat.spectral_bandwidth(y=sig,sr=sr)\n",
    "    sf = feat.spectral_flatness(y=sig)\n",
    "\n",
    "    features = [np.mean(rms), np.std(rms), np.min(rms), np.max(rms),\\\n",
    "                np.mean(sc), np.std(sc), np.min(sc), np.max(sc),\\\n",
    "                np.mean(sb), np.std(sb), np.min(sb), np.max(sb),\\\n",
    "                np.mean(sf), np.std(sf), np.min(sf), np.max(sf)]\n",
    "    return features\n",
    "\n",
    "def save_features(nb_files = len(df)):\n",
    "    features_and_labels = []\n",
    "    for line_num in tqdm(range(nb_files), unit=\"file\", desc=\"Generating features\"):\n",
    "        label_file = df.loc[line_num, \"label\"]\n",
    "        file_path = df.loc[line_num, \"relative_path\"]\n",
    "        features = extract_features(file_path)\n",
    "        features_and_labels.append((features, label_file))\n",
    "\n",
    "    features_and_labels = pd.DataFrame(features_and_labels, columns=[\"features\", \"label\"])\n",
    "    print(\"Global shape : \", features_and_labels.shape)\n",
    "    print(features_and_labels.head())\n",
    "\n",
    "    print(\"Saving features...\")\n",
    "    os.mkdir(\"numpy_data\") if not os.path.exists(\"numpy_data\") else None\n",
    "    np.save(os.path.join(\"numpy_data\", \"features.npy\"), features_and_labels[\"features\"])\n",
    "    print(\"Features saved !\")\n",
    "\n",
    "# save_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23168, 16)\n",
      "(23168,)\n"
     ]
    }
   ],
   "source": [
    "def get_spectrograms_from_file(file_path):\n",
    "    audio_specs = np.load(file_path)\n",
    "    return np.array(audio_specs.tolist())\n",
    "\n",
    "def get_labels_from_file(file_path):\n",
    "    label_files = np.load(file_path)\n",
    "    return np.array(label_files.tolist())\n",
    "\n",
    "def get_features_from_file(file_path):\n",
    "    features = np.load(file_path, allow_pickle=True)\n",
    "    return np.array(features.tolist())\n",
    "\n",
    "X = get_features_from_file(os.path.join(os.getcwd(),\"numpy_data\", \"features.npy\"))\n",
    "# X = pd.DataFrame(get_spectrograms_from_file(os.path.join(os.getcwd(),\"numpy_data\", \"audio_mfccs.npy\")))\n",
    "y = get_labels_from_file(os.path.join(os.getcwd(),\"numpy_data\", \"label_files.npy\"))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "assert len(X[0]) == 16, \"Wrong number of features !\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make features as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23168/23168 [00:29<00:00, 780.68 Element/s]\n"
     ]
    }
   ],
   "source": [
    "features=[\"rms_mean\",\"rms_std\", \"rms_min\", \"rms_max\", \"sc_mean\", \"sc_std\", \"sc_min\", \"sc_max\", \"sb_mean\", \"sb_std\", \"sb_min\", \"sb_max\", \"sf_mean\", \"sf_std\", \"sf_min\", \"sf_max\"]\n",
    "X_with_features_columns = pd.DataFrame(columns=features)\n",
    "\n",
    "for i, X_element in tqdm(enumerate(X), unit=\" Element\", total=X.shape[0]):\n",
    "    for j, feature in enumerate(X_element):\n",
    "        X_with_features_columns.loc[i, features[j]] = feature\n",
    "X = X_with_features_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training, testing (and validation) datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train contains 17376 files of shape (16,)\n",
      "X_test contains 5792 files of shape (16,)\n",
      "\n",
      "Features are : ['rms_mean', 'rms_std', 'rms_min', 'rms_max', 'sc_mean', 'sc_std', 'sc_min', 'sc_max', 'sb_mean', 'sb_std', 'sb_min', 'sb_max', 'sf_mean', 'sf_std', 'sf_min', 'sf_max']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>rms_min</th>\n",
       "      <th>rms_max</th>\n",
       "      <th>sc_mean</th>\n",
       "      <th>sc_std</th>\n",
       "      <th>sc_min</th>\n",
       "      <th>sc_max</th>\n",
       "      <th>sb_mean</th>\n",
       "      <th>sb_std</th>\n",
       "      <th>sb_min</th>\n",
       "      <th>sb_max</th>\n",
       "      <th>sf_mean</th>\n",
       "      <th>sf_std</th>\n",
       "      <th>sf_min</th>\n",
       "      <th>sf_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13536</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>30702.030623</td>\n",
       "      <td>1572.580532</td>\n",
       "      <td>28470.014592</td>\n",
       "      <td>36850.646852</td>\n",
       "      <td>24030.567117</td>\n",
       "      <td>764.07085</td>\n",
       "      <td>22303.222473</td>\n",
       "      <td>27100.27179</td>\n",
       "      <td>0.014827</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.049404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>0.00034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>32608.137948</td>\n",
       "      <td>1606.662465</td>\n",
       "      <td>29800.845142</td>\n",
       "      <td>38906.10698</td>\n",
       "      <td>24728.087656</td>\n",
       "      <td>512.30152</td>\n",
       "      <td>23324.005944</td>\n",
       "      <td>26382.538997</td>\n",
       "      <td>0.013381</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.027808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>0.00059</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>34680.066318</td>\n",
       "      <td>3075.335606</td>\n",
       "      <td>22736.514404</td>\n",
       "      <td>43918.748093</td>\n",
       "      <td>24490.830198</td>\n",
       "      <td>1036.674192</td>\n",
       "      <td>21397.083612</td>\n",
       "      <td>26696.343053</td>\n",
       "      <td>0.017704</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.081164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>30615.646103</td>\n",
       "      <td>1677.058799</td>\n",
       "      <td>28042.575955</td>\n",
       "      <td>35011.665955</td>\n",
       "      <td>24496.124273</td>\n",
       "      <td>1244.374612</td>\n",
       "      <td>18062.667725</td>\n",
       "      <td>26088.507472</td>\n",
       "      <td>0.009607</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.00567</td>\n",
       "      <td>0.018983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14763</th>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>37738.196099</td>\n",
       "      <td>4574.268149</td>\n",
       "      <td>27684.385163</td>\n",
       "      <td>49148.536777</td>\n",
       "      <td>24785.228915</td>\n",
       "      <td>927.791545</td>\n",
       "      <td>22300.302407</td>\n",
       "      <td>27851.902961</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>0.013248</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.11285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rms_mean   rms_std   rms_min   rms_max       sc_mean       sc_std  \\\n",
       "13536  0.000332  0.000032  0.000219  0.000393  30702.030623  1572.580532   \n",
       "1468    0.00034  0.000034  0.000225  0.000414  32608.137948  1606.662465   \n",
       "9719    0.00059  0.000132  0.000333  0.001038  34680.066318  3075.335606   \n",
       "7609   0.000402  0.000083  0.000256  0.000646  30615.646103  1677.058799   \n",
       "14763  0.000957  0.000205   0.00058  0.001453  37738.196099  4574.268149   \n",
       "\n",
       "             sc_min        sc_max       sb_mean       sb_std        sb_min  \\\n",
       "13536  28470.014592  36850.646852  24030.567117    764.07085  22303.222473   \n",
       "1468   29800.845142   38906.10698  24728.087656    512.30152  23324.005944   \n",
       "9719   22736.514404  43918.748093  24490.830198  1036.674192  21397.083612   \n",
       "7609   28042.575955  35011.665955  24496.124273  1244.374612  18062.667725   \n",
       "14763  27684.385163  49148.536777  24785.228915   927.791545  22300.302407   \n",
       "\n",
       "             sb_max   sf_mean    sf_std    sf_min    sf_max  \n",
       "13536   27100.27179  0.014827  0.005633   0.00997  0.049404  \n",
       "1468   26382.538997  0.013381  0.003185  0.008242  0.027808  \n",
       "9719   26696.343053  0.017704  0.007701  0.003582  0.081164  \n",
       "7609   26088.507472  0.009607  0.002646   0.00567  0.018983  \n",
       "14763  27851.902961  0.019865  0.013248  0.005781   0.11285  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,train_size=0.75)\n",
    "# X_train, X_validation, y_train, y_validation=train_test_split(X_train,y_train,train_size=0.8, random_state=64)\n",
    "\n",
    "print(f\"X_train contains {X_train.shape[0]} files of shape {X_train.shape[1:]}\")\n",
    "print(f\"X_test contains {X_test.shape[0]} files of shape {X_test.shape[1:]}\", end='\\n\\n')\n",
    "# print(f\"X_validation contains {X_validation.shape[0]} files of shape {X_validation.shape[1:]}\")\n",
    "\n",
    "print(f\"Features are : {X_train.columns.tolist()}\") \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N° of folds:  2\n",
      "N° of audios per fold:  11584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 1/2 [01:04<01:04, 64.32s/ fold]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/tristangclvs/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/notebook_scikit_learn.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tristangclvs/Documents/ENSC/3A/S9/Sp%C3%A9%20IA/projet/spe_IA_clics_odontocetes/notebook_scikit_learn.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mN° of audios per fold: \u001b[39m\u001b[39m\"\u001b[39m,X_train[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tristangclvs/Documents/ENSC/3A/S9/Sp%C3%A9%20IA/projet/spe_IA_clics_odontocetes/notebook_scikit_learn.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(n_fold), unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m fold\u001b[39m\u001b[39m\"\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tristangclvs/Documents/ENSC/3A/S9/Sp%C3%A9%20IA/projet/spe_IA_clics_odontocetes/notebook_scikit_learn.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train[i]\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m), y_train[i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tristangclvs/Documents/ENSC/3A/S9/Sp%C3%A9%20IA/projet/spe_IA_clics_odontocetes/notebook_scikit_learn.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# Make predictions on the validation set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tristangclvs/Documents/ENSC/3A/S9/Sp%C3%A9%20IA/projet/spe_IA_clics_odontocetes/notebook_scikit_learn.ipynb#X21sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test[i]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1303\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1301\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1303\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[1;32m   1304\u001b[0m     path_func(\n\u001b[1;32m   1305\u001b[0m         X,\n\u001b[1;32m   1306\u001b[0m         y,\n\u001b[1;32m   1307\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[1;32m   1308\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1309\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1310\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1311\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1312\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1313\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1314\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[1;32m   1315\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1316\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1317\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1318\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1319\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1320\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[1;32m   1321\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1322\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1323\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m   1324\u001b[0m     )\n\u001b[1;32m   1325\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[1;32m   1326\u001b[0m )\n\u001b[1;32m   1328\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:452\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    448\u001b[0m l2_reg_strength \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C\n\u001b[1;32m    449\u001b[0m iprint \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m101\u001b[39m][\n\u001b[1;32m    450\u001b[0m     np\u001b[39m.\u001b[39msearchsorted(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), verbose)\n\u001b[1;32m    451\u001b[0m ]\n\u001b[0;32m--> 452\u001b[0m opt_res \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[1;32m    453\u001b[0m     func,\n\u001b[1;32m    454\u001b[0m     w0,\n\u001b[1;32m    455\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    456\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    457\u001b[0m     args\u001b[39m=\u001b[39;49m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[1;32m    458\u001b[0m     options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39miprint\u001b[39;49m\u001b[39m\"\u001b[39;49m: iprint, \u001b[39m\"\u001b[39;49m\u001b[39mgtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: tol, \u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_iter},\n\u001b[1;32m    459\u001b[0m )\n\u001b[1;32m    460\u001b[0m n_iter_i \u001b[39m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    461\u001b[0m     solver,\n\u001b[1;32m    462\u001b[0m     opt_res,\n\u001b[1;32m    463\u001b[0m     max_iter,\n\u001b[1;32m    464\u001b[0m     extra_warning_msg\u001b[39m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    465\u001b[0m )\n\u001b[1;32m    466\u001b[0m w0, loss \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mx, opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    711\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    712\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    359\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    366\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    367\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     76\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 71\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:279\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     weights, intercept \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_intercept(coef)\n\u001b[0;32m--> 279\u001b[0m loss, grad_pointwise \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_loss\u001b[39m.\u001b[39;49mloss_gradient(\n\u001b[1;32m    280\u001b[0m     y_true\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    281\u001b[0m     raw_prediction\u001b[39m=\u001b[39;49mraw_prediction,\n\u001b[1;32m    282\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    283\u001b[0m     n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    285\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39msum()\n\u001b[1;32m    286\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml2_penalty(weights, l2_reg_strength)\n",
      "File \u001b[0;32m~/Documents/ENSC/3A/S9/Spé IA/projet/spe_IA_clics_odontocetes/.venv/lib/python3.11/site-packages/sklearn/_loss/loss.py:253\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[0;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m gradient_out\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m gradient_out\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    251\u001b[0m     gradient_out \u001b[39m=\u001b[39m gradient_out\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 253\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcloss\u001b[39m.\u001b[39;49mloss_gradient(\n\u001b[1;32m    254\u001b[0m     y_true\u001b[39m=\u001b[39;49my_true,\n\u001b[1;32m    255\u001b[0m     raw_prediction\u001b[39m=\u001b[39;49mraw_prediction,\n\u001b[1;32m    256\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    257\u001b[0m     loss_out\u001b[39m=\u001b[39;49mloss_out,\n\u001b[1;32m    258\u001b[0m     gradient_out\u001b[39m=\u001b[39;49mgradient_out,\n\u001b[1;32m    259\u001b[0m     n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m    260\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "n_fold = 2\n",
    "model = LogisticRegression()\n",
    "accuracy_scores = []\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X))\n",
    "\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "skf = StratifiedKFold(n_splits=n_fold)\n",
    "\n",
    "for train, test in skf.split(X_scaled, y):\n",
    "    X_train.append(train), X_test.append(test), y_train.append(train), y_test.append(test)\n",
    "\n",
    "print(\"N° of folds: \", len(X_train))\n",
    "print(\"N° of audios per fold: \",X_train[0].shape[0])\n",
    "\n",
    "for i in tqdm(range(n_fold), unit=\" fold\", desc=\"Training\"):\n",
    "    model.fit(X_train[i].reshape(-1,1), y_train[i])\n",
    "    # Make predictions on the validation set\n",
    "    y_pred = model.predict(X_test[i].reshape(-1, 1))\n",
    "    \n",
    "    # Calculate the accuracy score for this fold\n",
    "    acc = accuracy_score(y_test[i], y_pred)\n",
    "    \n",
    "    # Append the accuracy score to the list\n",
    "    accuracy_scores.append(acc)\n",
    "\n",
    "print(\"Accuracy scores: \", accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for prediction on random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def predict_on_random_sample(classifier, X_test, y_test):\n",
    "    random_index = random.randint(0, len(X_test)-1)\n",
    "    while random_index not in X_test.index:\n",
    "        random_index = random.randint(0, len(X_test)-1)\n",
    "    sample = X_test.loc[random_index]\n",
    "    print(\"Correct ✅\" if classifier.predict([sample])[0] == y_test[random_index] else \"Incorrect ❌\")\n",
    "    print(f'Prediction for sample {random_index:4}: {int(classifier.predict([sample])[0])}')\n",
    "    print(f'Actual label              : {int(y_test[random_index])}')\n",
    "\n",
    "    prob_table = f\"\"\"\n",
    "    Probabilities for each class:\n",
    "     _________________________\n",
    "    | Label   | Probability   |\n",
    "    |---------|---------------|\n",
    "    | 0       | {f\"{classifier.predict_proba([sample])[0][0]:.3f}\":13} |\n",
    "    | 1       | {f\"{classifier.predict_proba([sample])[0][1]:.3f}\":13} |\n",
    "    |_________|_______________|\"\"\"\n",
    "    display(ipd.Markdown(prob_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to display the confusion matrixes after fitting the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(classifier, X_test, y_test, cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    score_classifier = classifier.score(X_test, y_test)\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=[0,1],\n",
    "        cmap=cmap,\n",
    "        normalize='true',\n",
    "    )\n",
    "    plt.ylabel('Actual label', fontsize = 17);\n",
    "    plt.xlabel('Predicted label', fontsize = 17);\n",
    "    plt.title(f'Accuracy Score: {score_classifier:.3f}', size = 17);\n",
    "    plt.tick_params(labelsize= 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data\n",
    "\n",
    "For some models (e.g. Logistic Regression), data needs to be scaled. In order to do that we will use scikit-learn's StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=\"center\"> ---------- Logistic Regression ---------- </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log_reg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try a prediction on a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_random_sample(log_reg, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_log_reg = log_reg.score(X_test_scaled, y_test)\n",
    "print(f\"Logistic Regression score: {score_log_reg:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the confusion matrix on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(log_reg, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the ROC AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC AUC Score with Logistic Regression : {roc_auc_score(y_test, y_pred_log_reg)}\")\n",
    "print(f\"F1 Score with Logistic Regression      : {f1_score(y_test, y_pred_log_reg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=\"center\"> ---------- Decision Tree ---------- </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=15, random_state=0)\n",
    "tree_clf.fit(X_train.values, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test.values)\n",
    "print(f\"Accuracy: {tree_clf.score(X_test.values, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try a prediction on a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_random_sample(tree_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tree_clf = tree_clf.score(X_test.values, y_test)\n",
    "print(f\"Decision Tree score: {score_tree_clf:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to find the optimal `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of values to try for max_depth:\n",
    "max_depth_range = list(range(1, 15))\n",
    "\n",
    "# List to store the average RMSE for each value of max_depth:\n",
    "accuracy = []\n",
    "\n",
    "for depth in tqdm(max_depth_range, unit='depth', desc='Testing max_depth'):\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth = depth, \n",
    "                             random_state = 0)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    score = clf.score(X_test, y_test)\n",
    "    accuracy.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (10,7));\n",
    "\n",
    "ax.plot(max_depth_range,\n",
    "        accuracy,\n",
    "        lw=2,\n",
    "        color='k')\n",
    "\n",
    "ax.set_xlim([1, len(max_depth_range)])\n",
    "ax.set_ylim([.50, 1.00])\n",
    "ax.grid(True,\n",
    "        axis = 'both',\n",
    "        zorder = 0,\n",
    "        linestyle = ':',\n",
    "        color = 'k')\n",
    "\n",
    "yticks = ax.get_yticks()\n",
    "\n",
    "y_ticklist = []\n",
    "for tick in yticks:\n",
    "    y_ticklist.append(str(tick).ljust(4, '0')[0:4])\n",
    "ax.set_yticklabels(y_ticklist)\n",
    "ax.tick_params(labelsize = 18)\n",
    "ax.set_xlabel('max_depth', fontsize = 24)\n",
    "ax.set_ylabel('Accuracy', fontsize = 24)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "# Caution on the max_depth parameter, it makes the tree unreadable if too big\n",
    "# tree.plot_tree(tree_clf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(tree_clf, X_test.values, y_test, cmap=plt.cm.Greens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the ROC AUC & F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC AUC Score with Decision Tree : {roc_auc_score(y_test, y_pred_tree):.3f}\")\n",
    "print(f\"F1 Score with Decision Tree      : {f1_score(y_test, y_pred_tree):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=\"center\"> ---------- Bagged Tree ---------- </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier()\n",
    "\n",
    "bag_clf.fit(X_train.values, y_train)\n",
    "y_pred_bag = bag_clf.predict(X_test.values)\n",
    "print(f\"Accuracy: {bag_clf.score(X_test.values, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try prediction on a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_random_sample(bag_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_bag = bag_clf.score(X_test.values, y_test)\n",
    "print(f\"Logistic Regression score: {score_bag:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(bag_clf, X_test.values, y_test, cmap=plt.cm.Purples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check ROC AUC & F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC AUC Score with Bagged Tree : {roc_auc_score(y_test, y_pred_bag):.3f}\")\n",
    "print(f\"F1 Score with Bagged Tree      : {f1_score(y_test, y_pred_bag):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=\"center\"> ---------- Random Forest ---------- </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=100)\n",
    "forest_clf.fit(X_train.values, y_train)\n",
    "y_pred_forest = forest_clf.predict(X_test.values)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_forest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try predicting on a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_random_sample(forest_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_forest = forest_clf.score(X_test.values, y_test)\n",
    "print(f\"Logistic Regression score: {score_forest:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(forest_clf, X_test.values, y_test, cmap=plt.cm.Oranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the ROC AUC & F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC AUC Score with Random Forest : {roc_auc_score(y_test, y_pred_forest):.3f}\")\n",
    "print(f\"F1 Score with Random Forest      : {f1_score(y_test, y_pred_forest):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the importance of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(forest_clf.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False)\n",
    "importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train.values, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test.values)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_random_sample(xgb_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_xgb = xgb_clf.score(X_test.values, y_test)\n",
    "print(f\"XGB score: {score_xgb:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(xgb_clf, X_test.values, y_test, cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check ROC AUC & F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC AUC Score with XGB : {roc_auc_score(y_test, y_pred_xgb):.3f}\")\n",
    "print(f\"F1 Score with XGB      : {f1_score(y_test, y_pred_xgb):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "scores = cross_val_score(xgb_clf, X_train, y_train, cv=5)\n",
    "print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
    " \n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "kf_cv_scores = cross_val_score(xgb_clf, X_train, y_train, cv=kfold )\n",
    "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap of previous models and their respective scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.get_params()\n",
    "type(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort descending by score\n",
    "classifiers_names = [\"Logistic Regression\", \"Decision Tree\", \"Bagging\", \"Random Forest\", \"XGBClassifier\"]\n",
    "classifiers_scores = [score_log_reg, score_tree_clf, score_bag, score_forest, score_xgb]\n",
    "\n",
    "classifiers_f1_scores = [f1_score(y_test, y_pred_log_reg), f1_score(y_test, y_pred_tree), f1_score(y_test, y_pred_bag), f1_score(y_test, y_pred_forest), f1_score(y_test, y_pred_xgb)]\n",
    "\n",
    "classifiers_and_scores = list(zip(classifiers_names, classifiers_scores, classifiers_f1_scores))\n",
    "classifiers_and_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "scores_lines = [f\"| **{name}** | **{score:.3f}** | **{f1:.3f}** |\\n\" for index, (name, score, f1) in enumerate(classifiers_and_scores)]\n",
    "\n",
    "scores_table = f\"\"\"\n",
    "<div align=\"center\">\n",
    "    <h2>Classifiers scores</h2>\n",
    "\n",
    "| <h3>Classifier</h3>   | <h3>Score</h3>   | <h3>F1 Score</h3>   |\n",
    "|:---------:|:---------------:|\n",
    "{\"\".join(scores_lines)}\n",
    "\"\"\"\n",
    "\n",
    "display(ipd.Markdown(scores_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best classifier seems to be the XGB classifier, thus we will make predictions on the test waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are ** 950 ** audio files in the test dataset.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/tristangclvs/Documents/ENSC/3A/S9/Spé ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/tristangclvs/Documents/ENSC/3A/S9/Spé ...</td>\n",
       "      <td>0.197364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/tristangclvs/Documents/ENSC/3A/S9/Spé ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/tristangclvs/Documents/ENSC/3A/S9/Spé ...</td>\n",
       "      <td>0.826255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/tristangclvs/Documents/ENSC/3A/S9/Spé ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       relative_path     label\n",
       "0  /Users/tristangclvs/Documents/ENSC/3A/S9/Spé ...  0.000000\n",
       "1  /Users/tristangclvs/Documents/ENSC/3A/S9/Spé ...  0.197364\n",
       "2  /Users/tristangclvs/Documents/ENSC/3A/S9/Spé ...  1.000000\n",
       "3  /Users/tristangclvs/Documents/ENSC/3A/S9/Spé ...  0.826255\n",
       "4  /Users/tristangclvs/Documents/ENSC/3A/S9/Spé ...  0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_path = Path.cwd() / \".dataset\"\n",
    "\n",
    "# Read metadata file\n",
    "labels_file = download_path / \"Y_random_Xwjr6aB.csv\"\n",
    "df_test = pd.read_csv(labels_file)\n",
    "\n",
    "# Construct file path by concatenating folder and file name\n",
    "df_test[\"relative_path\"] = str(download_path) + \"/X_test/\" + df_test[\"id\"]\n",
    "df_test.drop(columns=[\"id\"], inplace=True)\n",
    "df_test.rename(columns={\"pos_label\": \"label\"}, inplace=True)\n",
    "# invert relative_path and label columns positions\n",
    "df_test = df_test[[\"relative_path\", \"label\"]]\n",
    "print(f\"There are ** {len(df_test)} ** audio files in the test dataset.\", end=\"\\n\\n\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "audio_util = AudioUtil()\n",
    "predictions = []\n",
    "\n",
    "for line_num in tqdm(range(len(df_test)), unit=\"file\", desc=\"Predicting labels\"):\n",
    "    test_audio_file = df_test.loc[line_num, \"relative_path\"]\n",
    "    test_file_features = np.array(extract_features(test_audio_file))\n",
    "    \n",
    "    # Predict the label of the audio file\n",
    "    prediction = xgb_clf.predict(test_file_features.reshape(1, -1))\n",
    "\n",
    "    # Print the predicted label\n",
    "    if prediction > 0.5:\n",
    "        predictions.append([df_test.loc[line_num, \"relative_path\"].split(sep='/')[-1], 1])\n",
    "    else:\n",
    "        predictions.append([df_test.loc[line_num, \"relative_path\"].split(sep='/')[-1], 0])\n",
    "\n",
    "predictions = pd.DataFrame(predictions, columns=[\"id\", \"pos_label\"])\n",
    "\n",
    "now = datetime.now()\n",
    "date = now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "predictions.to_csv(f\"Y_predict_{date}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://scikit-learn.org/stable/_static/ml_map.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to create and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_not_Cnn():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Dense(256, input_shape=(40,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Hidden layers\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "    model.summary()\n",
    "   \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Reshape((40, 1), input_shape=(40,)))\n",
    "\n",
    "    # Add a Lambda layer to add the batch size and channel dimensions\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1)))\n",
    "\n",
    "    # Add the first convolutional layer\n",
    "    model.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 1), activation='relu', strides=(1, 1))) \n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "    # Add the second convolutional layer\n",
    "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 1), activation='relu', strides=(1, 1), padding='same')) \n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "    # Flatten the output from the convolutional layers\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "is_cnn = \"CNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class Reshape(nn.Module):\n",
    "#     def __init__(self, shape):\n",
    "#         super(Reshape, self).__init__()\n",
    "#         self.shape = shape\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return x.view(x.size(0), *self.shape)\n",
    "\n",
    "# class CustomModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomModel, self).__init__()\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             Reshape((1, 40)),\n",
    "#             nn.Conv2d(1, 256, kernel_size=(3, 1), stride=(1, 1)),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Conv2d(256, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(1280, 256),  # Adjust the input size based on the output size of the previous layer\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(256, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "\n",
    "# def build_model():\n",
    "#     return CustomModel()\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = build_model()\n",
    "\n",
    "# # Print the model summary\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 200\n",
    "num_batch_size = 32\n",
    "\n",
    "# Create an EarlyStopping callback montinotoring 'val_loss'\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_validation, y_validation), verbose=1, callbacks=[early_stopping_callback]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = model.evaluate(X_test,y_test,verbose=0)\n",
    "\n",
    "for metric_name, result in zip(model.metrics_names, evaluation_results):\n",
    "    print(f\"{metric_name}: {result:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model depending on date and accuracy\n",
    "# Get date\n",
    "now = datetime.now()\n",
    "date = now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "model.save(os.path.join(os.getcwd(),\"models\",f\"model_{date}_{evaluation_results[1]:.4f}_{is_cnn}.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model with test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from tensorflow.keras.models import load_model\n",
    "options = [model for model in os.listdir(os.path.join(os.getcwd(),\"models\")) if model.endswith(\".h5\")]\n",
    "dropdown = widgets.Dropdown(options=options, value=options[0], description='Select a model:')\n",
    "button = widgets.Button(description='Show selected model')\n",
    "\n",
    "output = widgets.Output()\n",
    "selected_model = model\n",
    "def on_button_click(b):\n",
    "    global selected_model\n",
    "    with output:\n",
    "        selected_model = load_model(os.path.join(os.getcwd(),\"models\",dropdown.value))\n",
    "        print(f\"Selected model: {dropdown.value}\")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "display(dropdown)\n",
    "display(button)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = Path.cwd() / \".dataset\"\n",
    "\n",
    "# Read metadata file\n",
    "labels_file = download_path / \"Y_random_Xwjr6aB.csv\"\n",
    "df_test = pd.read_csv(labels_file)\n",
    "\n",
    "# Construct file path by concatenating folder and file name\n",
    "df_test[\"relative_path\"] = str(download_path) + \"/X_test/\" + df_test[\"id\"]\n",
    "df_test.drop(columns=[\"id\"], inplace=True)\n",
    "df_test.rename(columns={\"pos_label\": \"label\"}, inplace=True)\n",
    "# invert relative_path and label columns positions\n",
    "df_test = df_test[[\"relative_path\", \"label\"]]\n",
    "print(f\"There are ** {len(df_test)} ** audio files in the test dataset.\", end=\"\\n\\n\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrograms_test(nb_files = len(df_test)):\n",
    "    audio_util = AudioUtil()\n",
    "    labels_predicted = np.empty(0)\n",
    "    files_with_labels = []\n",
    "    audio_mfccs = []\n",
    "    labels_files = np.empty(0)\n",
    "    features_and_labels = []\n",
    "    print(\"Starting mfccs generation...\")\n",
    "    for line_num in tqdm(range(nb_files), unit=\"file\", desc=\"Generating mfccs\"):\n",
    "        file_path = df_test.loc[line_num, \"relative_path\"]\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        mfccs = audio_util.extract_mfccs(file_path)\n",
    "        \n",
    "        audio_mfccs.append(mfccs)\n",
    "        labels_files = np.append(labels_files, df_test.loc[line_num, \"label\"])\n",
    "\n",
    "        single_prediction = model.predict(mfccs.reshape(1,40), verbose=0)\n",
    "        labels_predicted = np.append(labels_predicted, single_prediction[0][0])\n",
    "        features_and_labels.append((mfccs, df_test.loc[line_num, \"label\"]))\n",
    "\n",
    "        files_with_labels.append([file_name, labels_predicted[-1]])\n",
    "    print(\"Mfccs generated !\", end='\\n\\n')\n",
    "    \n",
    "    files_with_labels = pd.DataFrame(files_with_labels, columns=[\"id\", \"label\"])\n",
    "    print(files_with_labels.head())\n",
    "    \n",
    "    # Save the csv file with the predictions\n",
    "    files_with_labels.to_csv(\"Y_test_predictions.csv\", index=False)\n",
    "\n",
    "    print(\"Saving mfccs...\")\n",
    "    os.mkdir(\"numpy_data\") if not os.path.exists(\"numpy_data\") else None\n",
    "    np.save(os.path.join(\"numpy_data\", \"test_audio_mfccs.npy\"), audio_mfccs)\n",
    "    np.save(os.path.join(\"numpy_data\", \"test_label_files.npy\"), labels_files)\n",
    "    print(\"Mfccs saved !\")\n",
    "    \n",
    "    features_and_labels = pd.DataFrame(features_and_labels, columns=[\"mfccs\", \"label\"])\n",
    "\n",
    "    print(\"Global shape : \", features_and_labels.shape)\n",
    "    print(features_and_labels.head())\n",
    "\n",
    "# save_spectrograms_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the AudioUtil class\n",
    "test_audio_util = AudioUtil()\n",
    "predictions = []\n",
    "\n",
    "for line_num in tqdm(range(len(df_test)), unit=\"file\", desc=\"Predicting labels\"):\n",
    "    test_audio_file = df_test.loc[line_num, \"relative_path\"]\n",
    "    test_mfccs = test_audio_util.extract_mfccs(test_audio_file)\n",
    "    \n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model(f\"models/model_31-10-2023_14-39-36_0.9668_CNN.h5\")\n",
    "\n",
    "    # Predict the label of the audio file\n",
    "    prediction = model.predict(test_mfccs.reshape(1,40), verbose=0);\n",
    "\n",
    "    # Print the predicted label\n",
    "    if prediction > 0.5:\n",
    "        predictions.append([df_test.loc[line_num, \"relative_path\"].split(sep='/')[-1], 1])\n",
    "    else:\n",
    "        predictions.append([df_test.loc[line_num, \"relative_path\"].split(sep='/')[-1], 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for prediction in predictions:\n",
    "    if prediction[1] == 1:\n",
    "        print(prediction, i)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the ROC AUC score with sklearn\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "X_testing = get_spectrograms_from_file(os.path.join(os.getcwd(),\"numpy_data\", \"test_audio_mfccs.npy\"))\n",
    "# y_testing = np.load(os.path.join(os.getcwd(),\"numpy_data\", \"test_label_files.npy\"))\n",
    "y_pred_keras = model.predict(X_test).ravel()\n",
    "y_pred_keras = np.where(y_pred_keras > 0.5, 1, 0)\n",
    "print(y_pred_keras, end=\"\\n\\n\")\n",
    "print(roc_auc_score(y_test, y_pred_keras))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the F1 score with sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, y_pred_keras))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the csv file with the predictions and the file names\n",
    "# predictions = [[df_test.loc[line_num, \"relative_path\"].split(sep='/')[-1], y_pred_keras[i]] for i, line_num in enumerate(range(len(df_test)))]\n",
    "df_predictions = pd.DataFrame(predictions, columns=[\"id\", \"label\"])\n",
    "df_predictions.to_csv(\"Y_test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
